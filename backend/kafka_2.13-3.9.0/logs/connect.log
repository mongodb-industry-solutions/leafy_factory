[2025-01-20 15:09:22,569] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2025-01-20 15:09:23,006] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2025-01-20 15:09:22,570] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1000)
[2025-01-20 15:09:23,007] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Client requested disconnect from node 2147483647 (org.apache.kafka.clients.NetworkClient:344)
[2025-01-20 15:09:23,007] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Requesting disconnect from last known coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1013)
[2025-01-20 15:09:23,008] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Client requested disconnect from node 2147483647 (org.apache.kafka.clients.NetworkClient:344)
[2025-01-20 15:09:23,012] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Discovered group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2025-01-20 15:09:23,012] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2025-01-20 15:09:23,012] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2025-01-20 15:09:23,013] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1013)
[2025-01-20 15:09:23,012] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2025-01-20 15:09:23,026] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1000)
[2025-01-20 15:09:23,026] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Requesting disconnect from last known coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1013)
[2025-01-20 15:09:23,113] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Discovered group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2025-01-20 15:09:23,113] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Discovered group coordinator 192.168.1.3:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2025-01-20 15:09:32,838] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-binlog-client (io.debezium.util.Threads:287)
[2025-01-20 15:09:32,852] INFO [mariadb-connector|task-0] Stopped reading binlog after 52 events, last recorded offset: {ts_sec=1737404706, file=mariadb-bin.000001, pos=858561, server_id=1, event=1} (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:1218)
[2025-01-20 15:09:32,920] INFO [mariadb-connector|task-0] Connected to binlog at localhost:3306, starting at BinlogOffsetContext{sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=BinlogSourceInfo{currentGtid='null', currentBinlogFilename='mariadb-bin.000001', currentBinlogPosition=858520, currentRowNumber=3, serverId=1, sourceTime=2025-01-20T20:25:06Z, threadId=-1, currentQuery='null', tableIds=[leafy_factory.machines], databaseName='leafy_factory'}, snapshotCompleted=true, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet='null', currentGtidSet='null', restartBinlogFilename='mariadb-bin.000001', restartBinlogPosition=858561, restartRowsToSkip=0, restartEventsToSkip=1, currentEventLengthInBytes=41, inTransaction=false, transactionId='null', incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]} (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:1232)
[2025-01-20 15:09:34,886] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:15, serverValue:964732}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:09:41,171] INFO [mongodb-sink-connector|task-0] Exception in monitor thread while connecting to server ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:696)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:574)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:410)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:369)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:157)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1116)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1103)
	at java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:489)
	at java.base/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:483)
	at java.base/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:70)
	at java.base/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1462)
	at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:1068)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:110)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:135)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:713)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:571)
	... 5 more
[2025-01-20 15:09:41,219] INFO [mongodb-sink-connector|task-0] Exception in monitor thread while connecting to server ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:696)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:574)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:410)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:369)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:157)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1116)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1103)
	at java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:489)
	at java.base/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:483)
	at java.base/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:70)
	at java.base/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1462)
	at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:1068)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:110)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:135)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:713)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:571)
	... 5 more
[2025-01-20 15:09:41,363] INFO [mongodb-sink-connector|task-0] Exception in monitor thread while connecting to server ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:76)
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:696)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:574)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:410)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:369)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:221)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:157)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:278)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:304)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:346)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:796)
	at java.base/java.net.Socket$SocketInputStream.implRead(Socket.java:1116)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:1103)
	at java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:489)
	at java.base/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:483)
	at java.base/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:70)
	at java.base/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1462)
	at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:1068)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:110)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:135)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:713)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:571)
	... 5 more
[2025-01-20 15:09:41,626] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:16, serverValue:551103}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:09:41,626] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-00.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=330403750, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-00.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-01.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c1dbb787d307faf2dda8d, counter=17}, lastWriteDate=Mon Jan 20 15:09:41 CST 2025, lastUpdateTimeNanos=493609068744333} (org.mongodb.driver.cluster:71)
[2025-01-20 15:09:41,744] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:17, serverValue:734772}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:09:41,744] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-02.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=411142083, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-02.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-01.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az4'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c21139efd3fe85ee0bc23, counter=20}, lastWriteDate=Mon Jan 20 15:09:41 CST 2025, lastUpdateTimeNanos=493609186936791} (org.mongodb.driver.cluster:71)
[2025-01-20 15:09:41,818] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:18, serverValue:964734}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:09:41,819] INFO [mongodb-sink-connector|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-01.n0kts.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=339697000, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-01.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-01.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000110, setVersion=71, topologyVersion=TopologyVersion{processId=677c26ebac34048efa73e114, counter=15}, lastWriteDate=Mon Jan 20 15:09:41 CST 2025, lastUpdateTimeNanos=493609261460541} (org.mongodb.driver.cluster:71)
[2025-01-20 15:09:41,820] INFO [mongodb-sink-connector|task-0] Discovered replica set primary ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-20 15:09:42,177] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:19, serverValue:551104}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:09:42,266] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:20, serverValue:734773}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:19:19,048] INFO [mariadb-connector|task-0] 4 records sent during previous 00:54:12.161, last recorded offset of {server=kafka} partition is {ts_sec=1737407958, file=mariadb-bin.000001, pos=0, row=1, server_id=1} (io.debezium.connector.common.BaseSourceTask:351)
[2025-01-20 15:19:19,111] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 52 : {kafka.leafy_factory.work_orders=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-20 15:19:19,259] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 56 : {kafka.leafy_factory.product_cost=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-20 15:19:20,015] INFO [mongodb-sink-connector|task-0] Opened connection [connectionId{localValue:21, serverValue:964877}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-20 15:19:23,118] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 4 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-20 15:19:23,658] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: cached metadata has changed from (version3: {kafka.leafy_factory.products=[NO_RACKS], kafka.leafy_factory.products_raw_materials=[NO_RACKS], kafka.leafy_factory.production_lines=[NO_RACKS], kafka.leafy_factory.raw_materials=[NO_RACKS], kafka.leafy_factory.factories=[NO_RACKS], kafka.leafy_factory.machines=[NO_RACKS]}) at the beginning of the rebalance to (version13: {kafka.leafy_factory.products=[NO_RACKS], kafka.leafy_factory.production_lines=[NO_RACKS], kafka.leafy_factory.products_raw_materials=[NO_RACKS], kafka.leafy_factory.raw_materials=[NO_RACKS], kafka.leafy_factory.factories=[NO_RACKS], kafka.leafy_factory.product_cost=[NO_RACKS], kafka.leafy_factory.machines=[NO_RACKS], kafka.leafy_factory.work_orders=[NO_RACKS]}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-20 15:19:24,190] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions kafka.leafy_factory.factories-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2025-01-20 15:19:24,202] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2025-01-20 15:19:24,212] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=2, memberId='connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2025-01-20 15:19:24,215] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 2: {connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76=Assignment(partitions=[kafka.leafy_factory.products-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.factories-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.work_orders-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2025-01-20 15:19:24,231] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=2, memberId='connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2025-01-20 15:19:24,237] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[kafka.leafy_factory.products-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.factories-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.work_orders-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2025-01-20 15:19:24,239] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: kafka.leafy_factory.factories-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.work_orders-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2025-01-20 15:19:24,248] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition kafka.leafy_factory.product_cost-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2025-01-20 15:19:24,249] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition kafka.leafy_factory.work_orders-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2025-01-20 15:19:24,256] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.products-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,257] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.raw_materials-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,258] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.production_lines-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,259] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.products_raw_materials-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,259] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.factories-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,259] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.machines-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:19:24,261] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition kafka.leafy_factory.product_cost-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-20 15:19:24,261] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition kafka.leafy_factory.work_orders-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-20 15:19:24,270] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialValueStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = id_job,id_cost,id_product,id_work,id_machine,id_production_data,id_production_line,id_jobs_machines
	document.id.strategy.partial.value.projection.type = AllowList
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = kafka.leafy_factory.product_cost
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-20 15:19:24,282] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialValueStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = id_job,id_cost,id_product,id_work,id_machine,id_production_data,id_production_line,id_jobs_machines
	document.id.strategy.partial.value.projection.type = AllowList
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = kafka.leafy_factory.work_orders
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-20 15:19:59,191] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 60 : {kafka.leafy_factory.jobs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-20 15:19:59,326] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 63 : {kafka.leafy_factory.jobs_machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-20 15:20:03,141] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 6 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-20 15:22:43,222] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 4 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-20 15:22:53,232] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 4 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-20 15:23:13,898] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 73 : {kafka.leafy_factory.production_data=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-20 15:23:23,254] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 15 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-20 15:24:18,611] INFO [Worker clientId=connect-192.168.1.3:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2025-01-20 15:24:24,391] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Request joining group due to: cached metadata has changed from (version14: {kafka.leafy_factory.products=[NO_RACKS], kafka.leafy_factory.production_lines=[NO_RACKS], kafka.leafy_factory.products_raw_materials=[NO_RACKS], kafka.leafy_factory.raw_materials=[NO_RACKS], kafka.leafy_factory.factories=[NO_RACKS], kafka.leafy_factory.product_cost=[NO_RACKS], kafka.leafy_factory.machines=[NO_RACKS], kafka.leafy_factory.work_orders=[NO_RACKS]}) at the beginning of the rebalance to (version15: {kafka.leafy_factory.products=[NO_RACKS], kafka.leafy_factory.production_data=[NO_RACKS], kafka.leafy_factory.jobs=[NO_RACKS], kafka.leafy_factory.production_lines=[NO_RACKS], kafka.leafy_factory.products_raw_materials=[NO_RACKS], kafka.leafy_factory.raw_materials=[NO_RACKS], kafka.leafy_factory.factories=[NO_RACKS], kafka.leafy_factory.product_cost=[NO_RACKS], kafka.leafy_factory.jobs_machines=[NO_RACKS], kafka.leafy_factory.machines=[NO_RACKS], kafka.leafy_factory.work_orders=[NO_RACKS]}) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-20 15:24:24,898] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Revoke previously assigned partitions kafka.leafy_factory.factories-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.work_orders-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2025-01-20 15:24:24,899] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2025-01-20 15:24:24,904] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2025-01-20 15:24:24,916] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Finished assignment for group at generation 3: {connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76=Assignment(partitions=[kafka.leafy_factory.products-0, kafka.leafy_factory.production_data-0, kafka.leafy_factory.jobs-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.factories-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.jobs_machines-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.work_orders-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2025-01-20 15:24:24,923] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mongodb-sink-connector-0-a1bf0f73-7653-4f59-a40a-e6c0400b7a76', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2025-01-20 15:24:24,924] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Notifying assignor about the new Assignment(partitions=[kafka.leafy_factory.products-0, kafka.leafy_factory.production_data-0, kafka.leafy_factory.jobs-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.factories-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.jobs_machines-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.work_orders-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2025-01-20 15:24:24,924] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Adding newly assigned partitions: kafka.leafy_factory.factories-0, kafka.leafy_factory.jobs-0, kafka.leafy_factory.jobs_machines-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.production_data-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.work_orders-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2025-01-20 15:24:24,927] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition kafka.leafy_factory.production_data-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2025-01-20 15:24:24,927] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition kafka.leafy_factory.jobs-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2025-01-20 15:24:24,928] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Found no committed offset for partition kafka.leafy_factory.jobs_machines-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1508)
[2025-01-20 15:24:24,928] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.products-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,929] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.raw_materials-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,929] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.production_lines-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,929] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.products_raw_materials-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,930] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.factories-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,930] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.product_cost-0 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,930] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.work_orders-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,930] INFO [mongodb-sink-connector|task-0] Setting offset for partition kafka.leafy_factory.machines-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerUtils:209)
[2025-01-20 15:24:24,931] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition kafka.leafy_factory.production_data-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-20 15:24:24,932] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition kafka.leafy_factory.jobs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-20 15:24:24,932] INFO [mongodb-sink-connector|task-0] [Consumer clientId=connector-consumer-mongodb-sink-connector-0, groupId=connect-mongodb-sink-connector] Resetting offset for partition kafka.leafy_factory.jobs_machines-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.3:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-20 15:24:24,948] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialValueStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = id_job,id_cost,id_product,id_work,id_machine,id_production_data,id_production_line,id_jobs_machines
	document.id.strategy.partial.value.projection.type = AllowList
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = kafka.leafy_factory.production_data
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-20 15:24:24,951] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialValueStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = id_job,id_cost,id_product,id_work,id_machine,id_production_data,id_production_line,id_jobs_machines
	document.id.strategy.partial.value.projection.type = AllowList
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = kafka.leafy_factory.jobs
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-20 15:24:24,952] INFO [mongodb-sink-connector|task-0] MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialValueStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = id_job,id_cost,id_product,id_work,id_machine,id_production_data,id_production_line,id_jobs_machines
	document.id.strategy.partial.value.projection.type = AllowList
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = kafka.leafy_factory.jobs_machines
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
