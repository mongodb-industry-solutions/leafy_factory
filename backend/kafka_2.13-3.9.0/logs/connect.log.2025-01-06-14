[2025-01-06 14:20:16,507] INFO Successfully processed removal of connector 'mongodb-sink' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1005)
[2025-01-06 14:20:16,509] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connector mongodb-sink config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2432)
[2025-01-06 14:20:16,509] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:20:16,509] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:20:16,511] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:20:16 +0000] "DELETE /connectors/mongodb-sink HTTP/1.1" 204 0 "-" "curl/8.7.1" 50 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:20:16,513] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:20:16,516] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:20:16,516] INFO [mongodb-sink|worker] Stopping connector mongodb-sink (org.apache.kafka.connect.runtime.Worker:452)
[2025-01-06 14:20:16,516] INFO [mongodb-sink|task-0] Stopping task mongodb-sink-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2025-01-06 14:20:16,517] INFO [mongodb-sink|worker] Scheduled shutdown for WorkerConnector{id=mongodb-sink} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2025-01-06 14:20:16,517] INFO [mongodb-sink|task-0] Stopping MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:124)
[2025-01-06 14:20:16,518] INFO [mongodb-sink|worker] Completed shutdown for WorkerConnector{id=mongodb-sink} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2025-01-06 14:20:16,608] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Revoke previously assigned partitions kafka.leafy_factory.factories-0, kafka.leafy_factory.jobs-0, kafka.leafy_factory.jobs_machines-0, kafka.leafy_factory.machines-0, kafka.leafy_factory.product_cost-0, kafka.leafy_factory.production_lines-0, kafka.leafy_factory.products-0, kafka.leafy_factory.products_raw_materials-0, kafka.leafy_factory.raw_materials-0, kafka.leafy_factory.work_orders-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:80)
[2025-01-06 14:20:16,609] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Member connector-consumer-mongodb-sink-0-a12e531c-bbfa-4442-9030-fa7a666e3ecc sending LeaveGroup request to coordinator 192.168.1.5:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1174)
[2025-01-06 14:20:16,610] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2025-01-06 14:20:16,610] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-06 14:20:16,959] INFO [mongodb-sink|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:20:16,959] INFO [mongodb-sink|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:20:16,959] INFO [mongodb-sink|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:20:16,960] INFO [mongodb-sink|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:20:16,963] INFO [mongodb-sink|task-0] App info kafka.consumer for connector-consumer-mongodb-sink-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:20:16,968] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2735)
[2025-01-06 14:20:16,976] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2756)
[2025-01-06 14:20:16,976] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', leaderUrl='http://192.168.1.5:8083/', offset=9, connectorIds=[mariadb-connector], taskIds=[mariadb-connector-0], revokedConnectorIds=[mongodb-sink], revokedTaskIds=[mongodb-sink-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:20:16,977] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:20:16,977] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:20:16,977] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:20:16,977] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:20:16,979] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:20:16,982] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:20:16,983] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-c276e093-dd35-45c6-8158-ecaef799e464', leaderUrl='http://192.168.1.5:8083/', offset=9, connectorIds=[mariadb-connector], taskIds=[mariadb-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:20:16,983] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:20:16,983] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:20:21,374] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = test
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:20:21,384] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "aarch64", "version": "15.0"}, "platform": "Java/Oracle Corporation/23+37-2369", "application": {"name": "IST-Shared"}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='leafy_factory', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4fe9b00c]}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=ist-shared.n0kts.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-133bp7-shard-0', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@34cf9933]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='IST-Shared', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-01-06 14:20:21,585] INFO Adding discovered server ist-shared-shard-00-01.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:21,586] INFO Adding discovered server ist-shared-shard-00-02.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:21,587] INFO Adding discovered server ist-shared-shard-00-00.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,414] INFO Opened connection [connectionId{localValue:19, serverValue:6653}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,414] INFO Opened connection [connectionId{localValue:17, serverValue:11397}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,414] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-00.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=414972417, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-00.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c1dbb787d307faf2dda8d, counter=4}, lastWriteDate=Mon Jan 06 14:20:22 CST 2025, lastUpdateTimeNanos=103040334398750} (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,414] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-02.n0kts.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=412173959, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-02.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az4'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000010b, setVersion=71, topologyVersion=TopologyVersion{processId=677c21139efd3fe85ee0bc23, counter=6}, lastWriteDate=Mon Jan 06 14:20:22 CST 2025, lastUpdateTimeNanos=103040334394583} (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,415] INFO Setting max election id to 7fffffff000000000000010b from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,415] INFO Setting max set version to 71 from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,415] INFO Discovered replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,415] INFO Opened connection [connectionId{localValue:20, serverValue:6654}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,415] INFO Opened connection [connectionId{localValue:18, serverValue:11398}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,590] INFO Opened connection [connectionId{localValue:16, serverValue:4045}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,597] INFO Opened connection [connectionId{localValue:15, serverValue:4044}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:22,597] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-01.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=463733042, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-01.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c26ebac34048efa73e114, counter=3}, lastWriteDate=Mon Jan 06 14:20:22 CST 2025, lastUpdateTimeNanos=103040517587166} (org.mongodb.driver.cluster:71)
[2025-01-06 14:20:22,965] INFO Opened connection [connectionId{localValue:21, serverValue:11399}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:20:23,057] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = __default
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:20:23,150] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2025-01-06 14:20:23,168] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:20:21 +0000] "POST /connectors HTTP/1.1" 400 335 "-" "curl/8.7.1" 1974 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:21:04,134] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,135] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,135] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 2147483647 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,135] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,134] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,135] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 3157 due to node 0 being disconnected (elapsed time since creation: 381ms, elapsed time since send: 381ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2025-01-06 14:21:04,134] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,136] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 3187 due to node 0 being disconnected (elapsed time since creation: 408ms, elapsed time since send: 408ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2025-01-06 14:21:04,134] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,134] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,134] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,134] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,134] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,137] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cancelled in-flight FETCH request with correlation id 3151 due to node 0 being disconnected (elapsed time since creation: 408ms, elapsed time since send: 408ms, throttle time: 0ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient:364)
[2025-01-06 14:21:04,136] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Error sending fetch request (sessionId=487666362, epoch=3169) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2025-01-06 14:21:04,136] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Error sending fetch request (sessionId=785527705, epoch=3139) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2025-01-06 14:21:04,135] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Group coordinator 192.168.1.5:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1000)
[2025-01-06 14:21:04,137] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Error sending fetch request (sessionId=255562861, epoch=3133) to node 0: (org.apache.kafka.clients.FetchSessionHandler:618)
org.apache.kafka.common.errors.DisconnectException
[2025-01-06 14:21:04,189] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,189] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,190] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,190] WARN [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,192] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,192] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,192] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,196] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,238] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,239] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,239] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,238] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,240] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,239] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,239] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,240] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,244] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,244] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,245] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,246] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,307] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,307] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,334] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,334] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,341] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,341] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,342] WARN [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,342] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,344] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,345] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,355] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,355] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,358] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,358] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,398] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,398] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,400] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,400] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,460] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,461] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,523] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,523] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,548] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,549] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,565] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,568] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,580] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,581] WARN [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,610] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,612] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,614] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,615] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,629] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,629] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,645] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,646] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,668] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,669] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,939] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,940] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,941] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,941] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:04,985] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:04,985] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,052] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,052] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,060] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,060] WARN [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,061] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,062] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,063] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,064] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,068] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,068] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,070] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,070] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,105] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,106] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,649] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,649] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,734] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,735] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,735] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,735] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,759] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,760] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,807] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,808] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,839] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,839] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,893] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,893] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,906] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:87)
[2025-01-06 14:21:05,907] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:358)
[2025-01-06 14:21:05,913] INFO Stopped http_8083@a99c42c{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2025-01-06 14:21:05,914] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2025-01-06 14:21:05,921] INFO Stopped o.e.j.s.ServletContextHandler@6e017950{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler:1159)
[2025-01-06 14:21:05,921] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:387)
[2025-01-06 14:21:05,921] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:851)
[2025-01-06 14:21:05,921] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:808)
[2025-01-06 14:21:05,922] INFO [mariadb-connector|worker] Stopping connector mariadb-connector (org.apache.kafka.connect.runtime.Worker:452)
[2025-01-06 14:21:05,922] INFO [mariadb-connector|worker] Scheduled shutdown for WorkerConnector{id=mariadb-connector} (org.apache.kafka.connect.runtime.WorkerConnector:295)
[2025-01-06 14:21:05,922] INFO [mariadb-connector|worker] Completed shutdown for WorkerConnector{id=mariadb-connector} (org.apache.kafka.connect.runtime.WorkerConnector:315)
[2025-01-06 14:21:05,922] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,923] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:05,923] INFO [mariadb-connector|task-0] Stopping task mariadb-connector-0 (org.apache.kafka.connect.runtime.Worker:1048)
[2025-01-06 14:21:05,932] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:05,932] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,055] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,055] WARN [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,220] INFO [mariadb-connector|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:434)
[2025-01-06 14:21:06,305] INFO [mariadb-connector|task-0] Finished streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:325)
[2025-01-06 14:21:06,306] INFO [mariadb-connector|task-0] Stopped reading binlog after 32 events, last recorded offset: {ts_sec=1736193397, file=mariadb-bin.000001, pos=92885, server_id=1, event=1} (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:1218)
[2025-01-06 14:21:06,306] INFO [mariadb-connector|task-0] SignalProcessor stopped (io.debezium.pipeline.signal.SignalProcessor:127)
[2025-01-06 14:21:06,307] INFO [mariadb-connector|task-0] Debezium ServiceRegistry stopped. (io.debezium.service.DefaultServiceRegistry:105)
[2025-01-06 14:21:06,309] INFO [mariadb-connector|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-01-06 14:21:06,310] INFO [mariadb-connector|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-01-06 14:21:06,311] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2025-01-06 14:21:06,314] INFO [mariadb-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:06,314] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:06,314] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:06,314] INFO [mariadb-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:06,315] INFO [mariadb-connector|task-0] App info kafka.producer for kafka-schemahistory unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:06,315] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2025-01-06 14:21:06,317] INFO [mariadb-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:06,317] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:06,318] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:06,318] INFO [mariadb-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:06,318] INFO [mariadb-connector|task-0] App info kafka.producer for connector-producer-mariadb-connector-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:06,319] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2025-01-06 14:21:06,320] INFO [Producer clientId=connect-cluster-statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2025-01-06 14:21:06,655] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,656] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,773] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,774] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,843] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,843] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,853] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,854] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,886] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,887] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,895] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,895] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:06,957] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:06,958] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,690] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,690] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,786] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,787] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,793] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,794] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,845] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,846] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,856] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,856] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,857] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,857] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:07,960] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:07,960] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,597] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,598] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,727] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,728] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,796] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,797] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,848] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,849] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,859] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,859] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,859] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,860] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:08,962] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:08,962] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,507] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,507] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,606] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,607] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,770] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,771] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,808] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,809] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,851] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,851] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,861] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,862] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:09,964] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:09,965] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,520] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,521] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,551] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,551] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,814] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,814] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,830] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,830] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,853] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,854] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,863] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,863] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:10,966] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:10,966] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,532] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,533] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,554] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,554] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,828] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,829] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,831] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,832] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,855] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,855] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,855] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,856] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:11,968] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:11,969] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,409] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,410] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,545] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,546] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,733] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,734] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,833] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,834] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,857] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,858] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,901] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,902] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:12,970] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:12,971] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,214] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,215] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,557] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,557] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,742] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,743] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,748] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,748] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,859] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,860] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:13,972] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:13,973] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,047] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,048] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,217] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,217] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,570] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,571] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,750] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,751] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,756] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,756] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,861] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,862] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:14,995] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:14,996] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,021] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,022] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,087] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,087] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,583] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,584] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,720] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,720] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,758] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,759] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:15,863] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:15,863] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,022] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,023] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,045] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,045] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,127] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,128] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,598] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,599] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,723] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,723] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,760] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,762] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,865] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,866] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:16,935] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:16,935] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,016] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,017] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,057] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,058] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,510] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,511] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,726] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,727] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,775] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,776] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,867] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,868] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:17,906] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:17,907] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,018] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,019] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,099] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,100] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,524] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,525] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,728] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,728] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,777] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,777] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,870] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,870] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:18,910] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:18,911] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,021] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,022] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,129] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,130] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,536] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,537] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,730] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,731] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,779] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,780] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,872] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,873] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:19,907] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:19,908] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,023] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,024] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,171] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,172] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,546] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,547] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,732] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,733] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,782] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,782] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,844] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,845] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:20,874] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:20,875] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,026] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,027] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,110] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,110] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,560] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,560] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,648] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,648] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,734] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,735] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,744] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,745] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:21,877] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:21,878] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,029] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,029] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,047] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,047] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,472] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,473] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,551] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,551] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,737] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,737] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,768] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,768] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:22,879] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:22,880] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,031] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,032] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,091] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,091] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,485] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,486] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,553] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,554] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,768] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,768] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,769] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,769] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:23,881] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:23,882] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,033] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,034] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,132] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,132] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,397] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,397] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,555] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,556] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,721] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,721] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,771] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,772] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:24,883] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:24,883] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,035] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,035] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,068] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,068] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,309] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,309] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,451] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,452] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,744] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,745] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,774] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,775] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:25,885] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:25,886] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,038] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,038] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,101] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,102] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,220] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,221] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,387] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,387] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,746] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,747] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,777] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,777] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:26,888] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:26,888] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,085] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,086] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,140] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,141] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,234] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,234] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,268] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,269] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,658] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,658] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,780] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,781] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:27,890] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:27,891] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,088] INFO [Producer clientId=connect-cluster-configs] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,088] WARN [Producer clientId=connect-cluster-configs] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,145] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,146] WARN [AdminClient clientId=connect-cluster-shared-admin] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,178] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,178] WARN [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,270] INFO [Producer clientId=connect-cluster-statuses] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,271] WARN [Producer clientId=connect-cluster-statuses] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,664] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,665] WARN [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,783] WARN [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,843] INFO [Producer clientId=connect-cluster-offsets] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,844] WARN [Producer clientId=connect-cluster-offsets] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,927] ERROR [Producer clientId=connect-cluster-statuses] Interrupted while joining ioThread (org.apache.kafka.clients.producer.KafkaProducer:1407)
java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:378)
	at java.base/java.lang.Thread.join(Thread.java:2011)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1404)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1375)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1351)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1125)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1108)
	at org.apache.kafka.connect.util.KafkaBasedLog.lambda$stop$4(KafkaBasedLog.java:335)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:335)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:223)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:176)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:826)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:392)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:21:28,928] INFO [Producer clientId=connect-cluster-statuses] Proceeding to force close the producer since pending requests could not be completed within timeout 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1416)
[2025-01-06 14:21:28,929] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,929] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,929] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:320)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1133)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1120)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:299)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:21:28,929] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,930] ERROR Failed to write status update (org.apache.kafka.connect.storage.KafkaStatusBackingStore:320)
org.apache.kafka.common.KafkaException: Producer is closed forcefully.
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortBatches(RecordAccumulator.java:1133)
	at org.apache.kafka.clients.producer.internals.RecordAccumulator.abortIncompleteBatches(RecordAccumulator.java:1120)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:299)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:21:28,930] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,933] INFO App info kafka.producer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,933] WARN Failed to close KafkaBasedLog producer for topic connect-status with type org.apache.kafka.clients.producer.KafkaProducer (org.apache.kafka.common.utils.Utils:1127)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1406)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1375)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1351)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1125)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1108)
	at org.apache.kafka.connect.util.KafkaBasedLog.lambda$stop$4(KafkaBasedLog.java:335)
	at java.base/java.util.Optional.ifPresent(Optional.java:178)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:335)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:223)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:176)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:826)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:392)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:378)
	at java.base/java.lang.Thread.join(Thread.java:2011)
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1404)
	... 17 more
[2025-01-06 14:21:28,934] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2025-01-06 14:21:28,934] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-06 14:21:28,935] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1021)
[2025-01-06 14:21:28,935] WARN [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient:849)
[2025-01-06 14:21:28,936] ERROR [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Failed to close fetcher with a timeout(ms)=30000 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:1060)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeThrowInterruptException(ConsumerNetworkClient.java:537)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:298)
	at org.apache.kafka.clients.consumer.internals.Fetcher.maybeCloseFetchSessions(Fetcher.java:132)
	at org.apache.kafka.clients.consumer.internals.Fetcher.closeInternal(Fetcher.java:169)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.lambda$close$11(AbstractFetch.java:479)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:161)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:139)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.close(AbstractFetch.java:479)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.lambda$close$3(ClassicKafkaConsumer.java:1153)
	at org.apache.kafka.common.utils.Utils.swallow(Utils.java:1050)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1153)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1109)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1097)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1757)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1125)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1108)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:336)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:223)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:176)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:826)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:392)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.lang.InterruptedException
	... 27 more
[2025-01-06 14:21:28,937] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,937] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,938] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,938] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,940] INFO App info kafka.consumer for connect-cluster-statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,940] WARN Failed to close KafkaBasedLog consumer for topic connect-status with type org.apache.kafka.clients.consumer.KafkaConsumer (org.apache.kafka.common.utils.Utils:1127)
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeThrowInterruptException(ConsumerNetworkClient.java:537)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:298)
	at org.apache.kafka.clients.consumer.internals.Fetcher.maybeCloseFetchSessions(Fetcher.java:132)
	at org.apache.kafka.clients.consumer.internals.Fetcher.closeInternal(Fetcher.java:169)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.lambda$close$11(AbstractFetch.java:479)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:161)
	at org.apache.kafka.common.internals.IdempotentCloser.close(IdempotentCloser.java:139)
	at org.apache.kafka.clients.consumer.internals.AbstractFetch.close(AbstractFetch.java:479)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.lambda$close$3(ClassicKafkaConsumer.java:1153)
	at org.apache.kafka.common.utils.Utils.swallow(Utils.java:1050)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1153)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1109)
	at org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer.close(ClassicKafkaConsumer.java:1097)
	at org.apache.kafka.clients.consumer.KafkaConsumer.close(KafkaConsumer.java:1757)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1125)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1108)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:336)
	at org.apache.kafka.connect.storage.KafkaStatusBackingStore.stop(KafkaStatusBackingStore.java:223)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:176)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:826)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:392)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.lang.InterruptedException
	... 27 more
[2025-01-06 14:21:28,940] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2025-01-06 14:21:28,941] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:407)
[2025-01-06 14:21:28,941] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2025-01-06 14:21:28,942] WARN Failed to close KafkaBasedLog for config topic with type org.apache.kafka.connect.storage.KafkaConfigBackingStore$$Lambda/0x00003e00019cec88 (org.apache.kafka.common.utils.Utils:1127)
org.apache.kafka.connect.errors.ConnectException: Failed to stop KafkaBasedLog. Exiting without cleanly shutting down it's producer and consumer.
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:330)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1125)
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1108)
	at org.apache.kafka.connect.storage.KafkaConfigBackingStore.stop(KafkaConfigBackingStore.java:410)
	at org.apache.kafka.connect.runtime.AbstractHerder.stopServices(AbstractHerder.java:177)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.stopServices(DistributedHerder.java:826)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt(DistributedHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:392)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: java.lang.InterruptedException
	at java.base/java.lang.Object.wait0(Native Method)
	at java.base/java.lang.Object.wait(Object.java:378)
	at java.base/java.lang.Thread.join(Thread.java:2017)
	at java.base/java.lang.Thread.join(Thread.java:2093)
	at org.apache.kafka.connect.util.KafkaBasedLog.stop(KafkaBasedLog.java:328)
	... 12 more
[2025-01-06 14:21:28,942] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2025-01-06 14:21:28,942] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:250)
[2025-01-06 14:21:28,945] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:261)
[2025-01-06 14:21:28,945] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:317)
[2025-01-06 14:21:28,945] INFO [Producer clientId=connect-cluster-offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1382)
[2025-01-06 14:21:28,948] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,949] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,949] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,949] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,949] INFO App info kafka.producer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,950] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2025-01-06 14:21:28,950] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-06 14:21:28,950] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,950] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,951] INFO Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,951] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,953] INFO App info kafka.consumer for connect-cluster-offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,953] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:341)
[2025-01-06 14:21:28,953] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:263)
[2025-01-06 14:21:28,953] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,953] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,953] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,953] INFO App info kafka.connect for 192.168.1.5:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,953] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:271)
[2025-01-06 14:21:28,955] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1056)
[2025-01-06 14:21:28,955] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,955] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,955] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,956] INFO App info kafka.connect for connect-192.168.1.5:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,956] INFO App info kafka.admin.client for connect-cluster-shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:21:28,957] INFO [AdminClient clientId=connect-cluster-shared-admin] Metadata update failed (org.apache.kafka.clients.admin.internals.AdminMetadataManager:273)
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
[2025-01-06 14:21:28,957] INFO [AdminClient clientId=connect-cluster-shared-admin] Timed out 1 remaining operation(s) during close. (org.apache.kafka.clients.admin.KafkaAdminClient:1488)
[2025-01-06 14:21:28,958] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:21:28,958] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:21:28,958] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:21:28,959] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:394)
[2025-01-06 14:21:28,959] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:858)
[2025-01-06 14:21:28,959] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:92)
[2025-01-06 14:24:07,268] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-01-06 14:24:07,270] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 23, 23+37-2369
	jvm.classpath = /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Mac OS X, aarch64, 15.0
	os.vcpus = 11
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2025-01-06 14:24:07,271] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-01-06 14:24:07,282] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,312] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-01-06 14:24:07,390] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,390] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1 (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,394] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,394] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,406] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:120)
[2025-01-06 14:24:07,420] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,422] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,424] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@5a07e868 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,424] INFO Scanning plugins with ServiceLoaderScanner took 143 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2025-01-06 14:24:07,425] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mongodb (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,547] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mongodb/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,547] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1 (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,612] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,612] INFO Loading plugin from: /Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:07,748] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:07,748] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:76)
[2025-01-06 14:24:08,158] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@5a07e868 (org.apache.kafka.connect.runtime.isolation.PluginScanner:81)
[2025-01-06 14:24:08,158] INFO Scanning plugins with ReflectionScanner took 733 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:71)
[2025-01-06 14:24:08,159] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1/	com.mongodb.kafka.connect.MongoSinkConnector	sink	1.14.1
file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/mongodb-kafka-connect-mongodb-1.14.1/	com.mongodb.kafka.connect.MongoSourceConnector	source	1.14.1
file:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins/debezium-connector-mongodb/	io.debezium.connector.mongodb.MongoDbSinkConnector	sink	3.0.5.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:123)
[2025-01-06 14:24:08,159] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,159] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,160] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,161] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-01-06 14:24:08,162] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'ExtractNewDocumentState' to plugin 'io.debezium.connector.mongodb.transforms.ExtractNewDocumentState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'DebeziumMySql' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoSourceConnector' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'DebeziumMySqlConnectRestExtension' to plugin 'io.debezium.connector.mysql.rest.DebeziumMySqlConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoDbSinkConnector' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoDb' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MySqlConnector' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoDbSink' to plugin 'io.debezium.connector.mongodb.MongoDbSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'MongoDbConnector' to plugin 'io.debezium.connector.mongodb.MongoDbConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,163] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'ReadToInsertEvent' to plugin 'io.debezium.connector.mysql.transforms.ReadToInsertEvent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'DebeziumMongoDb' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,164] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'MongoSinkConnector' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'DebeziumMongoDbConnectRestExtension' to plugin 'io.debezium.connector.mongodb.rest.DebeziumMongoDbConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'MongoEventRouter' to plugin 'io.debezium.connector.mongodb.transforms.outbox.MongoEventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,165] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-01-06 14:24:08,179] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:371)
[2025-01-06 14:24:08,180] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:281)
[2025-01-06 14:24:08,181] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2025-01-06 14:24:08,201] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2025-01-06 14:24:08,202] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,202] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,202] INFO Kafka startTimeMs: 1736195048202 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,311] INFO Kafka cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.connect.runtime.WorkerConfig:298)
[2025-01-06 14:24:08,312] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:24:08,314] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:24:08,314] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:24:08,314] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:24:08,316] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:371)
[2025-01-06 14:24:08,320] INFO Logging initialized @1283ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-01-06 14:24:08,332] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:125)
[2025-01-06 14:24:08,332] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:196)
[2025-01-06 14:24:08,340] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 23+37-2369 (org.eclipse.jetty.server.Server:375)
[2025-01-06 14:24:08,347] INFO Started http_8083@59e4a044{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-01-06 14:24:08,347] INFO Started @1311ms (org.eclipse.jetty.server.Server:415)
[2025-01-06 14:24:08,354] INFO Advertised URI: http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2025-01-06 14:24:08,354] INFO REST server listening at http://192.168.1.5:8083/, advertising URL http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:216)
[2025-01-06 14:24:08,354] INFO Advertised URI: http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2025-01-06 14:24:08,354] INFO REST admin endpoints at http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-01-06 14:24:08,354] INFO Advertised URI: http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2025-01-06 14:24:08,355] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:45)
[2025-01-06 14:24:08,356] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:24:08,364] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,364] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,364] INFO Kafka startTimeMs: 1736195048364 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,366] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:24:08,366] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:24:08,373] INFO Advertised URI: http://192.168.1.5:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:416)
[2025-01-06 14:24:08,385] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,385] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,385] INFO Kafka startTimeMs: 1736195048385 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,386] INFO Kafka Connect worker initialization took 1117ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-01-06 14:24:08,386] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:67)
[2025-01-06 14:24:08,387] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2025-01-06 14:24:08,387] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:375)
[2025-01-06 14:24:08,387] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:233)
[2025-01-06 14:24:08,387] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:232)
[2025-01-06 14:24:08,387] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2025-01-06 14:24:08,388] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2025-01-06 14:24:08,389] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2025-01-06 14:24:08,389] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,389] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,389] INFO Kafka startTimeMs: 1736195048389 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,398] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:238)
[2025-01-06 14:24:08,412] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-01-06 14:24:08,412] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-01-06 14:24:08,413] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-01-06 14:24:08,569] INFO Started o.e.j.s.ServletContextHandler@9fd3b61{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-01-06 14:24:08,569] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:303)
[2025-01-06 14:24:08,569] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:77)
[2025-01-06 14:24:08,725] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:416)
[2025-01-06 14:24:08,727] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2025-01-06 14:24:08,735] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,741] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2025-01-06 14:24:08,741] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,741] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,741] INFO Kafka startTimeMs: 1736195048741 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,745] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2025-01-06 14:24:08,746] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,748] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,758] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2025-01-06 14:24:08,758] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,758] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,758] INFO Kafka startTimeMs: 1736195048758 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,761] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,765] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2025-01-06 14:24:08,765] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,766] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,784] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,785] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2025-01-06 14:24:08,785] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2025-01-06 14:24:08,785] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:249)
[2025-01-06 14:24:08,786] INFO Worker started (org.apache.kafka.connect.runtime.Worker:243)
[2025-01-06 14:24:08,786] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2025-01-06 14:24:08,853] INFO Created topic (name=connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:416)
[2025-01-06 14:24:08,853] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2025-01-06 14:24:08,853] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,855] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2025-01-06 14:24:08,855] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,855] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,855] INFO Kafka startTimeMs: 1736195048855 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,855] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2025-01-06 14:24:08,855] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,857] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2025-01-06 14:24:08,857] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,857] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,857] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,857] INFO Kafka startTimeMs: 1736195048857 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,861] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,862] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,867] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,867] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,867] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,867] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,867] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,867] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2025-01-06 14:24:08,867] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2025-01-06 14:24:08,869] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:378)
[2025-01-06 14:24:08,869] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:254)
[2025-01-06 14:24:08,897] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:416)
[2025-01-06 14:24:08,897] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2025-01-06 14:24:08,898] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,899] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2025-01-06 14:24:08,899] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,899] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,899] INFO Kafka startTimeMs: 1736195048899 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,899] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2025-01-06 14:24:08,900] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:08,901] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, offset.flush.interval.ms, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2025-01-06 14:24:08,901] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:08,901] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:08,901] INFO Kafka startTimeMs: 1736195048901 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:08,902] INFO [Producer clientId=connect-cluster-configs] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,903] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:08,904] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:579)
[2025-01-06 14:24:08,904] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:715)
[2025-01-06 14:24:08,911] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.5:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:407)
[2025-01-06 14:24:08,911] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:311)
[2025-01-06 14:24:08,911] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:313)
[2025-01-06 14:24:08,911] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:402)
[2025-01-06 14:24:08,915] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:09,692] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Discovered group coordinator 192.168.1.5:9092 (id: 2147483647 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:937)
[2025-01-06 14:24:09,694] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:24:09,694] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:24:09,706] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:24:09,713] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:24:09,742] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:24:09,743] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', leaderUrl='http://192.168.1.5:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:24:09,743] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:387)
[2025-01-06 14:24:09,743] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:24:09,743] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:24:09,788] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2510)
[2025-01-06 14:24:42,512] INFO Loading the custom source info struct maker plugin: io.debezium.connector.mysql.MySqlSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2025-01-06 14:24:42,927] INFO Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-01-06 14:24:42,930] INFO Successfully tested connection for jdbc:mysql://localhost:3306/?useInformationSchema=true&nullCatalogMeansCurrent=false&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=CONVERT_TO_NULL&connectTimeout=30000 with user 'root' (io.debezium.connector.binlog.BinlogConnector:66)
[2025-01-06 14:24:42,931] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-01-06 14:24:42,933] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2025-01-06 14:24:42,938] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connector mariadb-connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2025-01-06 14:24:42,938] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:24:42,938] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:24:42,940] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:24:42,942] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:24:42,942] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', leaderUrl='http://192.168.1.5:8083/', offset=2, connectorIds=[mariadb-connector], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:24:42,942] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:24:42,943] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connector mariadb-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2025-01-06 14:24:42,944] INFO [mariadb-connector|worker] Creating connector mariadb-connector of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:313)
[2025-01-06 14:24:42,945] INFO [mariadb-connector|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2025-01-06 14:24:42,945] INFO [mariadb-connector|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:24:42,946] INFO [mariadb-connector|worker] Instantiated connector mariadb-connector with version 3.0.5.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:335)
[2025-01-06 14:24:42,947] INFO [mariadb-connector|worker] Finished creating connector mariadb-connector (org.apache.kafka.connect.runtime.Worker:356)
[2025-01-06 14:24:42,947] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:24:42,949] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2025-01-06 14:24:42,950] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:24:42,952] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:24:42 +0000] "POST /connectors HTTP/1.1" 201 683 "-" "curl/8.7.1" 491 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:24:42,957] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Tasks [mariadb-connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2025-01-06 14:24:42,957] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:24:42,958] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:24:42,959] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:24:42,960] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:24:42,960] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', leaderUrl='http://192.168.1.5:8083/', offset=4, connectorIds=[mariadb-connector], taskIds=[mariadb-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:24:42,961] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:24:42,961] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting task mariadb-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2025-01-06 14:24:42,962] INFO [mariadb-connector|task-0] Creating task mariadb-connector-0 (org.apache.kafka.connect.runtime.Worker:646)
[2025-01-06 14:24:42,963] INFO [mariadb-connector|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mariadb-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2025-01-06 14:24:42,963] INFO [mariadb-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mariadb-connector
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:24:42,964] INFO [mariadb-connector|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] Instantiated task mariadb-connector-0 with version 3.0.5.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:665)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mariadb-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:678)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mariadb-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:684)
[2025-01-06 14:24:42,965] INFO [mariadb-connector|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mariadb-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2025-01-06 14:24:42,966] INFO [mariadb-connector|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1795)
[2025-01-06 14:24:42,967] INFO [mariadb-connector|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:371)
[2025-01-06 14:24:42,967] INFO [mariadb-connector|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = mariadb-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:24:42,967] INFO [mariadb-connector|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-mariadb-connector-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2025-01-06 14:24:42,967] INFO [mariadb-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:42,968] INFO [mariadb-connector|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2025-01-06 14:24:42,968] INFO [mariadb-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:42,968] INFO [mariadb-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:42,968] INFO [mariadb-connector|task-0] Kafka startTimeMs: 1736195082968 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:42,970] INFO [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:42,972] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:24:42,973] INFO [mariadb-connector|task-0] Starting MySqlConnectorTask with configuration:
   connector.class = io.debezium.connector.mysql.MySqlConnector
   database.user = root
   database.server.id = 184054
   database.history.kafka.bootstrap.servers = localhost:9092
   database.history.kafka.topic = db.history.leafy_factory
   database.server.name = leafy_factory
   schema.history.internal.kafka.bootstrap.servers = localhost:9092
   database.port = 3306
   include.schema.changes = false
   topic.prefix = kafka
   schema.history.internal.kafka.topic = db.history.internal
   task.class = io.debezium.connector.mysql.MySqlConnectorTask
   database.hostname = localhost
   database.password = ********
   name = mariadb-connector
   database.include.list = leafy_factory
 (io.debezium.connector.common.BaseSourceTask:250)
[2025-01-06 14:24:42,973] INFO [mariadb-connector|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.mysql.MySqlSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1701)
[2025-01-06 14:24:42,973] INFO [mariadb-connector|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.DefaultTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1401)
[2025-01-06 14:24:43,012] INFO [mariadb-connector|task-0] Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-01-06 14:24:43,016] INFO [mariadb-connector|task-0] No previous offsets found (io.debezium.connector.common.BaseSourceTask:536)
[2025-01-06 14:24:43,032] INFO [mariadb-connector|task-0] KafkaSchemaHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=kafka-schemahistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=kafka-schemahistory} (io.debezium.storage.kafka.history.KafkaSchemaHistory:245)
[2025-01-06 14:24:43,032] INFO [mariadb-connector|task-0] KafkaSchemaHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=kafka-schemahistory, linger.ms=0} (io.debezium.storage.kafka.history.KafkaSchemaHistory:246)
[2025-01-06 14:24:43,032] INFO [mariadb-connector|task-0] Requested thread factory for component MySqlConnector, id = kafka named = db-history-config-check (io.debezium.util.Threads:270)
[2025-01-06 14:24:43,033] INFO [mariadb-connector|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:587)
[2025-01-06 14:24:43,033] INFO [mariadb-connector|task-0] ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-schemahistory
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:371)
[2025-01-06 14:24:43,034] INFO [mariadb-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:43,035] INFO [mariadb-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:43,035] INFO [mariadb-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:43,035] INFO [mariadb-connector|task-0] Kafka startTimeMs: 1736195083034 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:43,036] INFO [mariadb-connector|task-0] [Producer clientId=kafka-schemahistory] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:43,088] INFO [mariadb-connector|task-0] Using 'SHOW MASTER STATUS' to get binary log status (io.debezium.connector.mysql.jdbc.MySqlConnection:41)
[2025-01-06 14:24:43,106] INFO [mariadb-connector|task-0] Closing connection before starting schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:123)
[2025-01-06 14:24:43,106] INFO [mariadb-connector|task-0] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:983)
[2025-01-06 14:24:43,106] INFO [mariadb-connector|task-0] Connector started for the first time. (io.debezium.connector.common.BaseSourceTask:89)
[2025-01-06 14:24:43,107] INFO [mariadb-connector|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-schemahistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = kafka-schemahistory
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2025-01-06 14:24:43,107] INFO [mariadb-connector|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:24:43,108] INFO [mariadb-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:43,108] INFO [mariadb-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:43,108] INFO [mariadb-connector|task-0] Kafka startTimeMs: 1736195083108 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:43,110] INFO [mariadb-connector|task-0] [Consumer clientId=kafka-schemahistory, groupId=kafka-schemahistory] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:24:43,111] INFO [mariadb-connector|task-0] [Consumer clientId=kafka-schemahistory, groupId=kafka-schemahistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1056)
[2025-01-06 14:24:43,111] INFO [mariadb-connector|task-0] [Consumer clientId=kafka-schemahistory, groupId=kafka-schemahistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-06 14:24:43,112] INFO [mariadb-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:24:43,112] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:24:43,112] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:24:43,112] INFO [mariadb-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] App info kafka.consumer for kafka-schemahistory unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-schemahistory
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:371)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] These configurations '[value.serializer, acks, batch.size, max.block.ms, buffer.memory, key.serializer, linger.ms]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:24:43,113] INFO [mariadb-connector|task-0] Kafka startTimeMs: 1736195083113 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:24:43,150] INFO [mariadb-connector|task-0] Database schema history topic '(name=db.history.internal, numPartitions=1, replicationFactor=default, replicasAssignments=null, configs={cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1})' created (io.debezium.storage.kafka.history.KafkaSchemaHistory:555)
[2025-01-06 14:24:43,150] INFO [mariadb-connector|task-0] App info kafka.admin.client for kafka-schemahistory unregistered (org.apache.kafka.common.utils.AppInfoParser:89)
[2025-01-06 14:24:43,150] INFO [mariadb-connector|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:685)
[2025-01-06 14:24:43,150] INFO [mariadb-connector|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:689)
[2025-01-06 14:24:43,151] INFO [mariadb-connector|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:695)
[2025-01-06 14:24:43,151] INFO [mariadb-connector|task-0] Reconnecting after finishing schema recovery (io.debezium.connector.mysql.MySqlConnectorTask:136)
[2025-01-06 14:24:43,178] INFO [mariadb-connector|task-0] No previous offset found (io.debezium.connector.mysql.MySqlConnectorTask:147)
[2025-01-06 14:24:43,185] INFO [mariadb-connector|task-0] Requested thread factory for component MySqlConnector, id = kafka named = SignalProcessor (io.debezium.util.Threads:270)
[2025-01-06 14:24:43,191] INFO [mariadb-connector|task-0] Requested thread factory for component MySqlConnector, id = kafka named = change-event-source-coordinator (io.debezium.util.Threads:270)
[2025-01-06 14:24:43,191] INFO [mariadb-connector|task-0] Requested thread factory for component MySqlConnector, id = kafka named = blocking-snapshot (io.debezium.util.Threads:270)
[2025-01-06 14:24:43,192] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-change-event-source-coordinator (io.debezium.util.Threads:287)
[2025-01-06 14:24:43,192] INFO [mariadb-connector|task-0] WorkerSourceTask{id=mariadb-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:280)
[2025-01-06 14:24:43,193] INFO [mariadb-connector|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:137)
[2025-01-06 14:24:43,193] INFO [mariadb-connector|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:140)
[2025-01-06 14:24:43,196] INFO [mariadb-connector|task-0] According to the connector configuration both schema and data will be snapshot. (io.debezium.relational.RelationalSnapshotChangeEventSource:282)
[2025-01-06 14:24:43,197] INFO [mariadb-connector|task-0] Snapshot step 1 - Preparing (io.debezium.relational.RelationalSnapshotChangeEventSource:135)
[2025-01-06 14:24:43,198] INFO [mariadb-connector|task-0] Snapshot step 2 - Determining captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:144)
[2025-01-06 14:24:43,198] INFO [mariadb-connector|task-0] Read list of available databases (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:116)
[2025-01-06 14:24:43,200] INFO [mariadb-connector|task-0] 	 list of available databases is: [information_schema, leafy_factory, mysql, performance_schema, sys, test] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:118)
[2025-01-06 14:24:43,200] INFO [mariadb-connector|task-0] Read list of available tables in each database (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:126)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] 	snapshot continuing with database(s): [leafy_factory] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:147)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.jobs_machines to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.product_cost to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.production_lines to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.products_raw_materials to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.machines to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.jobs to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.raw_materials to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.work_orders to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.products to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,241] INFO [mariadb-connector|task-0] Adding table leafy_factory.factories to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:350)
[2025-01-06 14:24:43,242] INFO [mariadb-connector|task-0] Created connection pool with 1 threads (io.debezium.relational.RelationalSnapshotChangeEventSource:236)
[2025-01-06 14:24:43,242] INFO [mariadb-connector|task-0] Snapshot step 3 - Locking captured tables [leafy_factory.factories, leafy_factory.jobs, leafy_factory.jobs_machines, leafy_factory.machines, leafy_factory.product_cost, leafy_factory.production_lines, leafy_factory.products, leafy_factory.products_raw_materials, leafy_factory.raw_materials, leafy_factory.work_orders] (io.debezium.relational.RelationalSnapshotChangeEventSource:153)
[2025-01-06 14:24:43,243] INFO [mariadb-connector|task-0] Flush and obtain global read lock to prevent writes to database (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:488)
[2025-01-06 14:24:43,244] INFO [mariadb-connector|task-0] Snapshot step 4 - Determining snapshot offset (io.debezium.relational.RelationalSnapshotChangeEventSource:159)
[2025-01-06 14:24:43,245] INFO [mariadb-connector|task-0] Read binlog position of MySQL primary server (io.debezium.connector.mysql.MySqlSnapshotChangeEventSource:58)
[2025-01-06 14:24:43,246] INFO [mariadb-connector|task-0] Snapshot step 5 - Reading structure of captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:162)
[2025-01-06 14:24:43,246] INFO [mariadb-connector|task-0] All eligible tables schema should be captured, capturing: [leafy_factory.factories, leafy_factory.jobs, leafy_factory.jobs_machines, leafy_factory.machines, leafy_factory.product_cost, leafy_factory.production_lines, leafy_factory.products, leafy_factory.products_raw_materials, leafy_factory.raw_materials, leafy_factory.work_orders] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:314)
[2025-01-06 14:24:43,814] INFO [mariadb-connector|task-0] Reading structure of database 'leafy_factory' (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:348)
[2025-01-06 14:24:43,896] INFO [mariadb-connector|task-0] Snapshot step 6 - Persisting schema history (io.debezium.relational.RelationalSnapshotChangeEventSource:166)
[2025-01-06 14:24:43,931] INFO [mariadb-connector|task-0] Releasing global read lock to enable MySQL writes (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:497)
[2025-01-06 14:24:43,932] INFO [mariadb-connector|task-0] Writes to MySQL tables prevented for a total of 00:00:00.688 (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:501)
[2025-01-06 14:24:43,932] INFO [mariadb-connector|task-0] Snapshot step 7 - Snapshotting data (io.debezium.relational.RelationalSnapshotChangeEventSource:178)
[2025-01-06 14:24:43,932] INFO [mariadb-connector|task-0] Creating snapshot worker pool with 1 worker thread(s) (io.debezium.relational.RelationalSnapshotChangeEventSource:480)
[2025-01-06 14:24:43,933] INFO [mariadb-connector|task-0] For table 'leafy_factory.factories' using select statement: 'SELECT `id_factory`, `factory_name`, `factory_location`, `factory_timestamp` FROM `leafy_factory`.`factories`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,935] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.factories is OptionalLong[0] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,935] INFO [mariadb-connector|task-0] For table 'leafy_factory.jobs' using select statement: 'SELECT `id_job`, `target_output`, `nOk_products`, `quality_rate`, `job_status`, `creation_date`, `work_id` FROM `leafy_factory`.`jobs`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,937] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.jobs is OptionalLong[4] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,937] INFO [mariadb-connector|task-0] For table 'leafy_factory.jobs_machines' using select statement: 'SELECT `id_jobs_machines`, `job_id`, `machine_id` FROM `leafy_factory`.`jobs_machines`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,939] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.jobs_machines is OptionalLong[8] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,939] INFO [mariadb-connector|task-0] For table 'leafy_factory.machines' using select statement: 'SELECT `id_machine`, `machine_status`, `last_maintenance`, `operator`, `avg_output`, `reject_count`, `production_line_id` FROM `leafy_factory`.`machines`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,940] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.machines is OptionalLong[4] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,940] INFO [mariadb-connector|task-0] For table 'leafy_factory.product_cost' using select statement: 'SELECT `id_cost`, `raw_material_cost_per_product`, `overhead_per_product`, `total_cost_per_product`, `cost_ok_with_overhead`, `cost_nok_with_overhead`, `actual_total_cost`, `work_id` FROM `leafy_factory`.`product_cost`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,941] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.product_cost is OptionalLong[28] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,941] INFO [mariadb-connector|task-0] For table 'leafy_factory.production_lines' using select statement: 'SELECT `id_production_line`, `factory_id` FROM `leafy_factory`.`production_lines`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,942] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.production_lines is OptionalLong[2] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,942] INFO [mariadb-connector|task-0] For table 'leafy_factory.products' using select statement: 'SELECT `id_product`, `product_name`, `product_description` FROM `leafy_factory`.`products`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,943] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.products is OptionalLong[2] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,943] INFO [mariadb-connector|task-0] For table 'leafy_factory.products_raw_materials' using select statement: 'SELECT `id_products_raw_materials`, `product_id`, `raw_material_id` FROM `leafy_factory`.`products_raw_materials`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,945] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.products_raw_materials is OptionalLong[9] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,945] INFO [mariadb-connector|task-0] For table 'leafy_factory.raw_materials' using select statement: 'SELECT `id_raw_material`, `item_code`, `raw_material_name`, `raw_material_description`, `unit_measurement`, `raw_material_stock`, `raw_material_status`, `raw_material_currency`, `cost_per_part` FROM `leafy_factory`.`raw_materials`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,946] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.raw_materials is OptionalLong[8] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,946] INFO [mariadb-connector|task-0] For table 'leafy_factory.work_orders' using select statement: 'SELECT `id_work`, `planned_start_date`, `planned_end_date`, `actual_start_date`, `actual_end_date`, `quantity`, `wo_status`, `creation_date`, `product_id`, `nOk_products` FROM `leafy_factory`.`work_orders`' (io.debezium.relational.RelationalSnapshotChangeEventSource:489)
[2025-01-06 14:24:43,947] INFO [mariadb-connector|task-0] Estimated row count for table leafy_factory.work_orders is OptionalLong[32] (io.debezium.connector.binlog.BinlogSnapshotChangeEventSource:554)
[2025-01-06 14:24:43,949] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.factories' (1 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,958] INFO [mariadb-connector|task-0] 	 Finished exporting 1 records for table 'leafy_factory.factories' (1 of 10 tables); total duration '00:00:00.009' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,959] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.jobs' (2 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,960] INFO [mariadb-connector|task-0] 	 Finished exporting 4 records for table 'leafy_factory.jobs' (2 of 10 tables); total duration '00:00:00.001' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,961] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.jobs_machines' (3 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,963] INFO [mariadb-connector|task-0] 	 Finished exporting 8 records for table 'leafy_factory.jobs_machines' (3 of 10 tables); total duration '00:00:00.002' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,963] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.machines' (4 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,965] INFO [mariadb-connector|task-0] 	 Finished exporting 4 records for table 'leafy_factory.machines' (4 of 10 tables); total duration '00:00:00.002' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,966] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.product_cost' (5 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,969] INFO [mariadb-connector|task-0] 	 Finished exporting 32 records for table 'leafy_factory.product_cost' (5 of 10 tables); total duration '00:00:00.003' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,970] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.production_lines' (6 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,973] INFO [mariadb-connector|task-0] 	 Finished exporting 2 records for table 'leafy_factory.production_lines' (6 of 10 tables); total duration '00:00:00.003' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,973] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.products' (7 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,976] INFO [mariadb-connector|task-0] 	 Finished exporting 2 records for table 'leafy_factory.products' (7 of 10 tables); total duration '00:00:00.002' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,976] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.products_raw_materials' (8 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,977] INFO [mariadb-connector|task-0] 	 Finished exporting 8 records for table 'leafy_factory.products_raw_materials' (8 of 10 tables); total duration '00:00:00.001' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,977] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.raw_materials' (9 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,979] INFO [mariadb-connector|task-0] 	 Finished exporting 8 records for table 'leafy_factory.raw_materials' (9 of 10 tables); total duration '00:00:00.002' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,979] INFO [mariadb-connector|task-0] Exporting data from table 'leafy_factory.work_orders' (10 of 10 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:614)
[2025-01-06 14:24:43,986] INFO [mariadb-connector|task-0] 	 Finished exporting 32 records for table 'leafy_factory.work_orders' (10 of 10 tables); total duration '00:00:00.007' (io.debezium.relational.RelationalSnapshotChangeEventSource:660)
[2025-01-06 14:24:43,987] INFO [mariadb-connector|task-0] Snapshot - Final stage (io.debezium.pipeline.source.AbstractSnapshotChangeEventSource:108)
[2025-01-06 14:24:43,987] INFO [mariadb-connector|task-0] Snapshot completed (io.debezium.pipeline.source.AbstractSnapshotChangeEventSource:112)
[2025-01-06 14:24:43,993] INFO [mariadb-connector|task-0] Snapshot ended with SnapshotResult [status=COMPLETED, offset=BinlogOffsetContext{sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=BinlogSourceInfo{currentGtid='null', currentBinlogFilename='mariadb-bin.000001', currentBinlogPosition=92885, currentRowNumber=0, serverId=0, sourceTime=2025-01-06T20:24:43Z, threadId=-1, currentQuery='null', tableIds=[leafy_factory.work_orders], databaseName='leafy_factory'}, snapshotCompleted=true, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet='null', currentGtidSet='null', restartBinlogFilename='mariadb-bin.000001', restartBinlogPosition=92885, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId='null', incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]}] (io.debezium.pipeline.ChangeEventSourceCoordinator:298)
[2025-01-06 14:24:43,996] INFO [mariadb-connector|task-0] Requested thread factory for component MySqlConnector, id = kafka named = binlog-client (io.debezium.util.Threads:270)
[2025-01-06 14:24:43,998] INFO [mariadb-connector|task-0] Enable ssl PREFERRED mode for connector kafka (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:1289)
[2025-01-06 14:24:44,002] INFO [mariadb-connector|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2025-01-06 14:24:44,002] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-SignalProcessor (io.debezium.util.Threads:287)
[2025-01-06 14:24:44,002] INFO [mariadb-connector|task-0] Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator:323)
[2025-01-06 14:24:44,003] INFO [mariadb-connector|task-0] Skip 0 events on streaming start (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:278)
[2025-01-06 14:24:44,003] INFO [mariadb-connector|task-0] Skip 0 rows on streaming start (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:282)
[2025-01-06 14:24:44,003] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-binlog-client (io.debezium.util.Threads:287)
[2025-01-06 14:24:44,004] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-binlog-client (io.debezium.util.Threads:287)
[2025-01-06 14:24:44,046] INFO [mariadb-connector|task-0] Connected to binlog at localhost:3306, starting at BinlogOffsetContext{sourceInfoSchema=Schema{io.debezium.connector.mysql.Source:STRUCT}, sourceInfo=BinlogSourceInfo{currentGtid='null', currentBinlogFilename='mariadb-bin.000001', currentBinlogPosition=92885, currentRowNumber=0, serverId=0, sourceTime=2025-01-06T20:24:43Z, threadId=-1, currentQuery='null', tableIds=[leafy_factory.work_orders], databaseName='leafy_factory'}, snapshotCompleted=true, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], restartGtidSet='null', currentGtidSet='null', restartBinlogFilename='mariadb-bin.000001', restartBinlogPosition=92885, restartRowsToSkip=0, restartEventsToSkip=0, currentEventLengthInBytes=0, inTransaction=false, transactionId='null', incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]} (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:1232)
[2025-01-06 14:24:44,046] INFO [mariadb-connector|task-0] Waiting for keepalive thread to start (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:299)
[2025-01-06 14:24:44,047] INFO [mariadb-connector|task-0] Creating thread debezium-mysqlconnector-kafka-binlog-client (io.debezium.util.Threads:287)
[2025-01-06 14:24:44,147] INFO [mariadb-connector|task-0] Keepalive thread is running (io.debezium.connector.binlog.BinlogStreamingChangeEventSource:306)
[2025-01-06 14:24:44,219] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 4 : {kafka.leafy_factory.factories=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:44,367] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {kafka.leafy_factory.jobs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:44,498] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 10 : {kafka.leafy_factory.jobs_machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:44,638] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 14 : {kafka.leafy_factory.machines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:44,770] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 19 : {kafka.leafy_factory.product_cost=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:44,888] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 26 : {kafka.leafy_factory.production_lines=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:45,024] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 37 : {kafka.leafy_factory.products=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:45,154] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 41 : {kafka.leafy_factory.products_raw_materials=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:45,296] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 45 : {kafka.leafy_factory.raw_materials=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:45,435] WARN [mariadb-connector|task-0] [Producer clientId=connector-producer-mariadb-connector-0] The metadata response from the cluster reported a recoverable issue with correlation id 50 : {kafka.leafy_factory.work_orders=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1218)
[2025-01-06 14:24:52,977] INFO [mariadb-connector|task-0|offsets] WorkerSourceTask{id=mariadb-connector-0} Committing offsets for 101 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:236)
[2025-01-06 14:27:30,737] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:27:30,742] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:27:30 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 19 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:27:41,543] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:27:41,545] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:27:41 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:28:24,109] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:28:24,111] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:28:24 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:28:53,396] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:28:53,398] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:28:53 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:29:50,107] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:29:50,111] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:29:50 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 12 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:30:02,949] ERROR Uncaught exception in REST call to /connector-plugins/MongoSinkConnector/config/validate (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 39] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 14:30:02,951] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:30:02 +0000] "PUT /connector-plugins/MongoSinkConnector/config/validate HTTP/1.1" 500 299 "-" "curl/8.7.1" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:30:21,518] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2025-01-06 14:30:21,522] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:30:21 +0000] "POST /connectors HTTP/1.1" 400 401 "-" "curl/8.7.1" 296 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:31:11,564] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.JsonMappingException: Unexpected character ('/' (code 47)): maybe a (non-standard) comment? (not recognized as one since Feature 'ALLOW_COMMENTS' not enabled for parser)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 800] (through reference chain: org.apache.kafka.connect.runtime.rest.entities.CreateConnectorRequest["config"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:402)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:361)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1937)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:572)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:440)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1493)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:348)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:185)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('/' (code 47)): maybe a (non-standard) comment? (not recognized as one since Feature 'ALLOW_COMMENTS' not enabled for parser)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 800]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:676)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._skipComment(UTF8StreamJsonParser.java:3278)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._skipWS2(UTF8StreamJsonParser.java:3077)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser._skipWS(UTF8StreamJsonParser.java:3053)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:1067)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:608)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:545)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:570)
	... 71 more
[2025-01-06 14:31:11,568] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:31:11 +0000] "POST /connectors HTTP/1.1" 500 391 "-" "curl/8.7.1" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:31:52,222] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:65)
com.fasterxml.jackson.databind.JsonMappingException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 801] (through reference chain: org.apache.kafka.connect.runtime.rest.entities.CreateConnectorRequest["config"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:402)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:361)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1937)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:572)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:440)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1493)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:348)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:185)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1575)
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('"' (code 34)): was expecting comma to separate Object entries
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 801]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:676)
	at com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextFieldName(UTF8StreamJsonParser.java:1065)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:608)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:545)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeWithErrorWrapping(BeanDeserializer.java:570)
	... 71 more
[2025-01-06 14:31:52,224] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:31:52 +0000] "POST /connectors HTTP/1.1" 500 329 "-" "curl/8.7.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:32:19,281] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialKeyStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = id_work_order,id_job,id_product
	document.id.strategy.partial.key.projection.type = none
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = test
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:32:19,326] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "aarch64", "version": "15.0"}, "platform": "Java/Oracle Corporation/23+37-2369", "application": {"name": "IST-Shared"}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='leafy_factory', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3e5963de]}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=ist-shared.n0kts.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-133bp7-shard-0', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@5a6977b8]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='IST-Shared', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-01-06 14:32:19,518] INFO Adding discovered server ist-shared-shard-00-01.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:19,539] INFO Adding discovered server ist-shared-shard-00-02.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:19,539] INFO Adding discovered server ist-shared-shard-00-00.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,563] INFO Opened connection [connectionId{localValue:1, serverValue:12326}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:20,563] INFO Opened connection [connectionId{localValue:5, serverValue:12325}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:20,563] INFO Opened connection [connectionId{localValue:3, serverValue:7107}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:20,563] INFO Opened connection [connectionId{localValue:2, serverValue:7108}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:20,569] INFO Opened connection [connectionId{localValue:4, serverValue:4503}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:20,570] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-01.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=562508458, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-01.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c26ebac34048efa73e114, counter=3}, lastWriteDate=Mon Jan 06 14:32:20 CST 2025, lastUpdateTimeNanos=103758494439000} (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,570] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-00.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=560603333, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-00.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c1dbb787d307faf2dda8d, counter=4}, lastWriteDate=Mon Jan 06 14:32:20 CST 2025, lastUpdateTimeNanos=103758486368708} (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,570] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-02.n0kts.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=560330375, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-02.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az4'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000010b, setVersion=71, topologyVersion=TopologyVersion{processId=677c21139efd3fe85ee0bc23, counter=6}, lastWriteDate=Mon Jan 06 14:32:20 CST 2025, lastUpdateTimeNanos=103758486333458} (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,573] INFO Setting max election id to 7fffffff000000000000010b from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,574] INFO Setting max set version to 71 from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,574] INFO Discovered replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:32:20,586] INFO Opened connection [connectionId{localValue:6, serverValue:4504}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:21,220] INFO Opened connection [connectionId{localValue:7, serverValue:12328}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:32:21,331] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialKeyStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = id_work_order,id_job,id_product
	document.id.strategy.partial.key.projection.type = none
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = __default
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:32:21,435] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2025-01-06 14:32:21,438] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:32:19 +0000] "POST /connectors HTTP/1.1" 400 416 "-" "curl/8.7.1" 2413 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:33:33,134] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialKeyStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = id_work_order,id_job,id_product
	document.id.strategy.partial.key.projection.type = ALLOWLIST
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = test
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:33:33,148] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "aarch64", "version": "15.0"}, "platform": "Java/Oracle Corporation/23+37-2369", "application": {"name": "IST-Shared"}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='leafy_factory', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3e5963de]}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=ist-shared.n0kts.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-133bp7-shard-0', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@1d7475b0]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='IST-Shared', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-01-06 14:33:33,230] INFO Adding discovered server ist-shared-shard-00-01.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,232] INFO Adding discovered server ist-shared-shard-00-02.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,232] INFO Adding discovered server ist-shared-shard-00-00.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,537] INFO Opened connection [connectionId{localValue:10, serverValue:12433}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:33,538] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-02.n0kts.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=194548000, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-02.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az4'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000010b, setVersion=71, topologyVersion=TopologyVersion{processId=677c21139efd3fe85ee0bc23, counter=6}, lastWriteDate=Mon Jan 06 14:33:33 CST 2025, lastUpdateTimeNanos=103831462643333} (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,539] INFO Setting max election id to 7fffffff000000000000010b from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,539] INFO Setting max set version to 71 from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,540] INFO Discovered replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,558] INFO Opened connection [connectionId{localValue:8, serverValue:4554}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:33,559] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-01.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=214467125, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-01.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c26ebac34048efa73e114, counter=3}, lastWriteDate=Mon Jan 06 14:33:33 CST 2025, lastUpdateTimeNanos=103831483700375} (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,623] INFO Opened connection [connectionId{localValue:12, serverValue:7161}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:33,623] INFO Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-00.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=287257500, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-00.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c1dbb787d307faf2dda8d, counter=4}, lastWriteDate=Mon Jan 06 14:33:33 CST 2025, lastUpdateTimeNanos=103831547996458} (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:33,631] INFO Opened connection [connectionId{localValue:13, serverValue:7162}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:33,639] INFO Opened connection [connectionId{localValue:11, serverValue:12432}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:33,658] INFO Opened connection [connectionId{localValue:9, serverValue:4555}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,180] INFO Opened connection [connectionId{localValue:14, serverValue:12435}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,278] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = leafy_factory
	delete.on.null.values = false
	delete.writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DeleteOneDefaultStrategy
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.PartialKeyStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = id_work_order,id_job,id_product
	document.id.strategy.partial.key.projection.type = ALLOWLIST
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = true
	errors.tolerance = all
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = __default
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:371)
[2025-01-06 14:33:34,375] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:371)
[2025-01-06 14:33:34,391] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Connector mongodb-sink config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2448)
[2025-01-06 14:33:34,392] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:33:34,392] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:33:34,393] INFO [0:0:0:0:0:0:0:1] - - [06/Jan/2025:20:33:32 +0000] "POST /connectors HTTP/1.1" 201 1111 "-" "curl/8.7.1" 1518 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-01-06 14:33:34,395] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:33:34,398] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:33:34,398] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', leaderUrl='http://192.168.1.5:8083/', offset=5, connectorIds=[mongodb-sink, mariadb-connector], taskIds=[mariadb-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:33:34,399] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 5 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:33:34,399] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connector mongodb-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2097)
[2025-01-06 14:33:34,399] INFO [mongodb-sink|worker] Creating connector mongodb-sink of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:313)
[2025-01-06 14:33:34,400] INFO [mongodb-sink|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2025-01-06 14:33:34,400] INFO [mongodb-sink|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:33:34,401] INFO [mongodb-sink|worker] Instantiated connector mongodb-sink with version 1.14.1 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:335)
[2025-01-06 14:33:34,401] INFO [mongodb-sink|worker] Finished creating connector mongodb-sink (org.apache.kafka.connect.runtime.Worker:356)
[2025-01-06 14:33:34,401] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:33:34,405] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2025-01-06 14:33:34,406] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:33:34,415] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Tasks [mongodb-sink-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2467)
[2025-01-06 14:33:34,415] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:243)
[2025-01-06 14:33:34,415] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:605)
[2025-01-06 14:33:34,416] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:666)
[2025-01-06 14:33:34,417] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:843)
[2025-01-06 14:33:34,418] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-192.168.1.5:8083-457a5d9e-6b73-45c2-ae1d-1087ca04b22e', leaderUrl='http://192.168.1.5:8083/', offset=7, connectorIds=[mongodb-sink, mariadb-connector], taskIds=[mongodb-sink-0, mariadb-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2648)
[2025-01-06 14:33:34,418] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1979)
[2025-01-06 14:33:34,418] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Starting task mongodb-sink-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2022)
[2025-01-06 14:33:34,421] INFO [mongodb-sink|task-0] Creating task mongodb-sink-0 (org.apache.kafka.connect.runtime.Worker:646)
[2025-01-06 14:33:34,422] INFO [mongodb-sink|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:371)
[2025-01-06 14:33:34,422] INFO [mongodb-sink|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:33:34,422] INFO [mongodb-sink|task-0] TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:371)
[2025-01-06 14:33:34,422] INFO [mongodb-sink|task-0] Instantiated task mongodb-sink-0 with version 1.14.1 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:665)
[2025-01-06 14:33:34,422] INFO [mongodb-sink|task-0] StringConverterConfig values: 
	converter.encoding = UTF-8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:371)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:371)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongodb-sink-0 using the connector config (org.apache.kafka.connect.runtime.Worker:680)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongodb-sink-0 using the connector config (org.apache.kafka.connect.runtime.Worker:686)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongodb-sink-0 using the worker config (org.apache.kafka.connect.runtime.Worker:691)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1795)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:371)
[2025-01-06 14:33:34,423] INFO [mongodb-sink|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = true
	errors.log.include.messages = true
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = all
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongodb-sink
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = []
	topics.regex = db_\.leafy_factory\..*
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:371)
[2025-01-06 14:33:34,425] INFO [mongodb-sink|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongodb-sink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongodb-sink
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:371)
[2025-01-06 14:33:34,425] INFO [mongodb-sink|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:270)
[2025-01-06 14:33:34,427] INFO [mongodb-sink|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2025-01-06 14:33:34,428] INFO [mongodb-sink|task-0] Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-01-06 14:33:34,428] INFO [mongodb-sink|task-0] Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-01-06 14:33:34,428] INFO [mongodb-sink|task-0] Kafka startTimeMs: 1736195614427 (org.apache.kafka.common.utils.AppInfoParser:127)
[2025-01-06 14:33:34,432] INFO [Worker clientId=connect-192.168.1.5:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2008)
[2025-01-06 14:33:34,432] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Subscribed to pattern: 'db_\.leafy_factory\..*' (org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer:534)
[2025-01-06 14:33:34,433] INFO [mongodb-sink|task-0] Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:66)
[2025-01-06 14:33:34,454] INFO [mongodb-sink|task-0] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.14.1"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "aarch64", "version": "15.0"}, "platform": "Java/Oracle Corporation/23+37-2369", "application": {"name": "IST-Shared"}} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=majority, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='leafy_factory', source='admin', password=<hidden>, mechanismProperties=<hidden>}, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3e5963de]}, clusterSettings={hosts=[127.0.0.1:27017], srvHost=ist-shared.n0kts.mongodb.net, srvServiceName=mongodb, mode=MULTIPLE, requiredClusterType=REPLICA_SET, requiredReplicaSetName='atlas-133bp7-shard-0', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=true, invalidHostNameAllowed=false, context=null}, applicationName='IST-Shared', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2025-01-06 14:33:34,460] INFO [mongodb-sink|task-0] WorkerSinkTask{id=mongodb-sink-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:325)
[2025-01-06 14:33:34,460] INFO [mongodb-sink|task-0] Adding discovered server ist-shared-shard-00-01.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,460] INFO [mongodb-sink|task-0] WorkerSinkTask{id=mongodb-sink-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:211)
[2025-01-06 14:33:34,460] INFO [mongodb-sink|task-0] Adding discovered server ist-shared-shard-00-02.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,460] INFO [mongodb-sink|task-0] Adding discovered server ist-shared-shard-00-00.n0kts.mongodb.net:27017 to client view of cluster (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,463] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Cluster ID: Sm3EnjWhQzyeGVfbRupNLg (org.apache.kafka.clients.Metadata:365)
[2025-01-06 14:33:34,463] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Discovered group coordinator 192.168.1.5:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:937)
[2025-01-06 14:33:34,464] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2025-01-06 14:33:34,471] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Request joining group due to: need to re-join with the given member-id: connector-consumer-mongodb-sink-0-5c539be9-f20b-48e9-8392-e30e31755dd2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1103)
[2025-01-06 14:33:34,471] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:605)
[2025-01-06 14:33:34,477] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-0-5c539be9-f20b-48e9-8392-e30e31755dd2', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:666)
[2025-01-06 14:33:34,479] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Finished assignment for group at generation 1: {connector-consumer-mongodb-sink-0-5c539be9-f20b-48e9-8392-e30e31755dd2=Assignment(partitions=[])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:664)
[2025-01-06 14:33:34,482] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mongodb-sink-0-5c539be9-f20b-48e9-8392-e30e31755dd2', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:843)
[2025-01-06 14:33:34,482] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:324)
[2025-01-06 14:33:34,483] INFO [mongodb-sink|task-0] [Consumer clientId=connector-consumer-mongodb-sink-0, groupId=connect-mongodb-sink] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:58)
[2025-01-06 14:33:34,842] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:19, serverValue:7164}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,842] INFO [mongodb-sink|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-00.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=270613500, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-00.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c1dbb787d307faf2dda8d, counter=4}, lastWriteDate=Mon Jan 06 14:33:34 CST 2025, lastUpdateTimeNanos=103832767606333} (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,923] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:20, serverValue:7163}] to ist-shared-shard-00-00.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,928] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:18, serverValue:12436}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,928] INFO [mongodb-sink|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-02.n0kts.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=361077125, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-02.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az4'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff000000000000010b, setVersion=71, topologyVersion=TopologyVersion{processId=677c21139efd3fe85ee0bc23, counter=6}, lastWriteDate=Mon Jan 06 14:33:34 CST 2025, lastUpdateTimeNanos=103832853178291} (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,929] INFO [mongodb-sink|task-0] Setting max election id to 7fffffff000000000000010b from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,929] INFO [mongodb-sink|task-0] Setting max set version to 71 from replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,930] INFO [mongodb-sink|task-0] Discovered replica set primary ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.cluster:71)
[2025-01-06 14:33:34,938] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:17, serverValue:12437}] to ist-shared-shard-00-02.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,959] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:16, serverValue:4556}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,969] INFO [mongodb-sink|task-0] Opened connection [connectionId{localValue:15, serverValue:4557}] to ist-shared-shard-00-01.n0kts.mongodb.net:27017 (org.mongodb.driver.connection:71)
[2025-01-06 14:33:34,969] INFO [mongodb-sink|task-0] Monitor thread successfully connected to server with description ServerDescription{address=ist-shared-shard-00-01.n0kts.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=386481833, setName='atlas-133bp7-shard-0', canonicalAddress=ist-shared-shard-00-01.n0kts.mongodb.net:27017, hosts=[ist-shared-shard-00-02.n0kts.mongodb.net:27017, ist-shared-shard-00-01.n0kts.mongodb.net:27017, ist-shared-shard-00-00.n0kts.mongodb.net:27017], passives=[], arbiters=[], primary='ist-shared-shard-00-02.n0kts.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='cac1-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='CA_CENTRAL_1'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=71, topologyVersion=TopologyVersion{processId=677c26ebac34048efa73e114, counter=3}, lastWriteDate=Mon Jan 06 14:33:34 CST 2025, lastUpdateTimeNanos=103832894159625} (org.mongodb.driver.cluster:71)
