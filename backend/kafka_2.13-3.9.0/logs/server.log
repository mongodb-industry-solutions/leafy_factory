[2025-01-06 17:02:02,706] WARN Session 0x1000626ec9d0000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:02:03,863] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:02:03,868] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:02:03,874] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-06 17:02:03,899] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2025-01-06 17:02:03,905] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:02:03,905] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:02:03,905] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:02:03,906] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:02:03,916] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:02:03,917] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:02:03,917] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:02:03,919] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,920] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,920] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,922] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-06 17:02:03,922] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,923] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,923] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,924] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:02:03,924] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-06 17:02:03,924] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:02:03,924] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:02:03,924] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:02:03,925] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:02:03,925] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:02:03,925] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,926] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:02:03,927] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-06 17:02:03,927] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:02:03,927] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:02:03,927] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:02:03,927] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:02:03,928] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:02:03,928] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:02:03,928] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:02:03,928] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,928] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,928] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,928] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,929] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:02:03,938] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:02:03,939] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:02:03,939] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:02:03,940] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-06 17:02:03,940] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,940] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,940] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,941] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:02:03,941] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,941] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,941] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:02:03,941] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:02:03,941] INFO Shutting down. (kafka.log.LogManager)
[2025-01-06 17:02:03,942] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:02:03,942] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:02:03,942] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:02:03,970] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs_machines-0] Wrote producer snapshot at offset 8 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:03,993] INFO [ProducerStateManager partition=connect-status-4] Wrote producer snapshot at offset 7 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,009] INFO [ProducerStateManager partition=connect-offsets-3] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,033] INFO [ProducerStateManager partition=__consumer_offsets-36] Wrote producer snapshot at offset 3 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,051] INFO [ProducerStateManager partition=connect-status-0] Wrote producer snapshot at offset 2 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,067] INFO [ProducerStateManager partition=db.history.internal-0] Wrote producer snapshot at offset 46 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,084] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs-0] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,101] INFO [ProducerStateManager partition=connect-configs-0] Wrote producer snapshot at offset 9 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,137] INFO [ProducerStateManager partition=connect-status-2] Wrote producer snapshot at offset 6 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,157] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 5 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,171] INFO [ProducerStateManager partition=__consumer_offsets-19] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,183] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 1 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,188] INFO [ProducerStateManager partition=kafka.leafy_factory.factories-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,226] INFO [ProducerStateManager partition=connect-status-3] Wrote producer snapshot at offset 5 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,243] INFO [ProducerStateManager partition=kafka.leafy_factory.machines-0] Wrote producer snapshot at offset 8 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,249] INFO [ProducerStateManager partition=kafka.leafy_factory.production_lines-0] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,266] INFO [ProducerStateManager partition=kafka.leafy_factory.work_orders-0] Wrote producer snapshot at offset 32 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,280] INFO [ProducerStateManager partition=kafka.leafy_factory.product_cost-0] Wrote producer snapshot at offset 32 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,300] INFO [ProducerStateManager partition=kafka.leafy_factory.raw_materials-0] Wrote producer snapshot at offset 16 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,321] INFO [ProducerStateManager partition=kafka.leafy_factory.products-0] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,348] INFO [ProducerStateManager partition=kafka.leafy_factory.products_raw_materials-0] Wrote producer snapshot at offset 16 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:02:04,391] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-06 17:02:04,393] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:02:04,394] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:02:04,394] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:02:04,394] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:02:04,413] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:02:04,518] INFO Session: 0x1000626ec9d0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:02:04,518] INFO EventThread shut down for session: 0x1000626ec9d0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:02:04,519] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:02:04,519] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,521] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,521] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,521] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,522] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:02:04,523] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-06 17:02:04,531] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-06 17:02:04,532] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:02:04,532] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:02:04,532] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:02:04,532] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-06 17:02:04,533] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:02:04,533] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-06 17:03:48,047] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,047] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,049] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,049] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,049] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,049] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,050] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:03:48,050] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:03:48,050] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:03:48,050] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-06 17:03:48,050] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-06 17:03:48,051] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:03:48,051] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-06 17:03:48,056] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9225652 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-06 17:03:48,057] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:03:48,057] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:03:48,058] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:03:48,062] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,062] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,077] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:host.name=192.168.1.5 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:os.arch=aarch64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:os.version=15.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,078] INFO Server environment:user.name=gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Server environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Server environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,079] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-06 17:03:48,080] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,080] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,080] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:03:48,080] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,081] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:03:48,083] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,083] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,083] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:03:48,083] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:03:48,083] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,086] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:03:48,086] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:03:48,087] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 22 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:03:48,091] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:03:48,100] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:03:48,100] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:03:48,100] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:03:48,100] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:03:48,103] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-06 17:03:48,103] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:03:48,104] INFO Snapshot loaded in 4 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:03:48,104] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:03:48,105] INFO Snapshot taken in 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:03:48,108] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-06 17:03:48,108] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-06 17:03:48,114] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-06 17:03:48,114] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-06 17:03:51,205] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-06 17:03:51,314] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-06 17:03:51,355] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:03:51,356] INFO starting (kafka.server.KafkaServer)
[2025-01-06 17:03:51,357] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-06 17:03:51,368] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:03:51,372] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,372] INFO Client environment:host.name=192.168.1.5 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,372] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,372] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,372] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,372] INFO Client environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.arch=aarch64 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.version=15.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:user.name=gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,373] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,374] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e403b4a (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:03:51,376] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-06 17:03:51,380] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:03:51,380] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:03:51,380] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:03:51,383] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64851, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:03:51,387] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-06 17:03:51,394] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10006ac1c3f0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:03:51,395] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:03:51,573] INFO Cluster ID = ENYvlSzpQfichNYMko35Tg (kafka.server.KafkaServer)
[2025-01-06 17:03:51,592] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-06 17:03:51,606] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:03:51,606] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:03:51,606] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:03:51,607] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:03:51,610] INFO [KafkaServer id=0] Rewriting /tmp/kafka-logs/meta.properties (kafka.server.KafkaServer)
[2025-01-06 17:03:51,629] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:03:51,632] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
[2025-01-06 17:03:51,636] INFO Loaded 0 logs in 6ms (kafka.log.LogManager)
[2025-01-06 17:03:51,637] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-06 17:03:51,637] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-06 17:03:51,672] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:03:51,679] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:03:51,683] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:03:51,695] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:03:51,819] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-06 17:03:51,826] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-06 17:03:51,827] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:03:51,837] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,837] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,837] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,837] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,838] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,843] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:03:51,843] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:03:51,851] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-06 17:03:51,861] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1736204631856,1736204631856,1,0,0,72064930315960320,206,0,25
 (kafka.zk.KafkaZkClient)
[2025-01-06 17:03:51,861] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.1.5:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2025-01-06 17:03:51,878] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,881] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2025-01-06 17:03:51,882] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,882] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,888] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:03:51,891] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:03:51,893] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:03:51,900] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:03:51,904] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:03:51,904] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:03:51,905] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-06 17:03:51,924] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:03:51,929] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:03:51,931] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:03:51,932] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:03:51,936] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:03:51,942] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-06 17:03:51,943] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-06 17:03:51,944] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:03:51,944] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:03:51,944] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:03:51,944] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:03:51,946] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:03:51,946] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:03:51,946] INFO Kafka startTimeMs: 1736204631944 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:03:51,946] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-06 17:03:52,103] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:03:52,130] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:05:25,187] INFO Creating topic connect-offsets with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:05:25,279] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-offsets-20, connect-offsets-6, connect-offsets-17, connect-offsets-15, connect-offsets-7, connect-offsets-24, connect-offsets-16, connect-offsets-3, connect-offsets-21, connect-offsets-11, connect-offsets-10, connect-offsets-2, connect-offsets-18, connect-offsets-23, connect-offsets-4, connect-offsets-12, connect-offsets-5, connect-offsets-13, connect-offsets-14, connect-offsets-0, connect-offsets-8, connect-offsets-9, connect-offsets-1, connect-offsets-19, connect-offsets-22) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:05:25,305] INFO [LogLoader partition=connect-offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,309] INFO Created log for partition connect-offsets-24 in /tmp/kafka-logs/connect-offsets-24 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,309] INFO [Partition connect-offsets-24 broker=0] No checkpointed highwatermark is found for partition connect-offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:05:25,310] INFO [Partition connect-offsets-24 broker=0] Log loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,323] INFO [LogLoader partition=connect-offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,323] INFO Created log for partition connect-offsets-9 in /tmp/kafka-logs/connect-offsets-9 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,324] INFO [Partition connect-offsets-9 broker=0] No checkpointed highwatermark is found for partition connect-offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:05:25,324] INFO [Partition connect-offsets-9 broker=0] Log loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,330] INFO [LogLoader partition=connect-offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,331] INFO Created log for partition connect-offsets-20 in /tmp/kafka-logs/connect-offsets-20 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,331] INFO [Partition connect-offsets-20 broker=0] No checkpointed highwatermark is found for partition connect-offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:05:25,331] INFO [Partition connect-offsets-20 broker=0] Log loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,338] INFO [LogLoader partition=connect-offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,338] INFO Created log for partition connect-offsets-5 in /tmp/kafka-logs/connect-offsets-5 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,338] INFO [Partition connect-offsets-5 broker=0] No checkpointed highwatermark is found for partition connect-offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:05:25,339] INFO [Partition connect-offsets-5 broker=0] Log loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,345] INFO [LogLoader partition=connect-offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,345] INFO Created log for partition connect-offsets-17 in /tmp/kafka-logs/connect-offsets-17 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,346] INFO [Partition connect-offsets-17 broker=0] No checkpointed highwatermark is found for partition connect-offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:05:25,346] INFO [Partition connect-offsets-17 broker=0] Log loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,359] INFO [LogLoader partition=connect-offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,359] INFO Created log for partition connect-offsets-2 in /tmp/kafka-logs/connect-offsets-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,360] INFO [Partition connect-offsets-2 broker=0] No checkpointed highwatermark is found for partition connect-offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:05:25,361] INFO [Partition connect-offsets-2 broker=0] Log loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,375] INFO [LogLoader partition=connect-offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,375] INFO Created log for partition connect-offsets-13 in /tmp/kafka-logs/connect-offsets-13 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,375] INFO [Partition connect-offsets-13 broker=0] No checkpointed highwatermark is found for partition connect-offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:05:25,375] INFO [Partition connect-offsets-13 broker=0] Log loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,383] INFO [LogLoader partition=connect-offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,383] INFO Created log for partition connect-offsets-8 in /tmp/kafka-logs/connect-offsets-8 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,384] INFO [Partition connect-offsets-8 broker=0] No checkpointed highwatermark is found for partition connect-offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:05:25,384] INFO [Partition connect-offsets-8 broker=0] Log loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,391] INFO [LogLoader partition=connect-offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,391] INFO Created log for partition connect-offsets-4 in /tmp/kafka-logs/connect-offsets-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,391] INFO [Partition connect-offsets-4 broker=0] No checkpointed highwatermark is found for partition connect-offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:05:25,391] INFO [Partition connect-offsets-4 broker=0] Log loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,400] INFO [LogLoader partition=connect-offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,400] INFO Created log for partition connect-offsets-23 in /tmp/kafka-logs/connect-offsets-23 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,400] INFO [Partition connect-offsets-23 broker=0] No checkpointed highwatermark is found for partition connect-offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:05:25,400] INFO [Partition connect-offsets-23 broker=0] Log loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,409] INFO [LogLoader partition=connect-offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,409] INFO Created log for partition connect-offsets-16 in /tmp/kafka-logs/connect-offsets-16 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,409] INFO [Partition connect-offsets-16 broker=0] No checkpointed highwatermark is found for partition connect-offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:05:25,409] INFO [Partition connect-offsets-16 broker=0] Log loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,415] INFO [LogLoader partition=connect-offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,415] INFO Created log for partition connect-offsets-1 in /tmp/kafka-logs/connect-offsets-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,415] INFO [Partition connect-offsets-1 broker=0] No checkpointed highwatermark is found for partition connect-offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:05:25,415] INFO [Partition connect-offsets-1 broker=0] Log loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,422] INFO [LogLoader partition=connect-offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,422] INFO Created log for partition connect-offsets-12 in /tmp/kafka-logs/connect-offsets-12 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,422] INFO [Partition connect-offsets-12 broker=0] No checkpointed highwatermark is found for partition connect-offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:05:25,422] INFO [Partition connect-offsets-12 broker=0] Log loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,428] INFO [LogLoader partition=connect-offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,429] INFO Created log for partition connect-offsets-11 in /tmp/kafka-logs/connect-offsets-11 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,429] INFO [Partition connect-offsets-11 broker=0] No checkpointed highwatermark is found for partition connect-offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:05:25,429] INFO [Partition connect-offsets-11 broker=0] Log loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,435] INFO [LogLoader partition=connect-offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,436] INFO Created log for partition connect-offsets-22 in /tmp/kafka-logs/connect-offsets-22 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,436] INFO [Partition connect-offsets-22 broker=0] No checkpointed highwatermark is found for partition connect-offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:05:25,436] INFO [Partition connect-offsets-22 broker=0] Log loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,443] INFO [LogLoader partition=connect-offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,443] INFO Created log for partition connect-offsets-7 in /tmp/kafka-logs/connect-offsets-7 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,443] INFO [Partition connect-offsets-7 broker=0] No checkpointed highwatermark is found for partition connect-offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:05:25,443] INFO [Partition connect-offsets-7 broker=0] Log loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,449] INFO [LogLoader partition=connect-offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,449] INFO Created log for partition connect-offsets-0 in /tmp/kafka-logs/connect-offsets-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,449] INFO [Partition connect-offsets-0 broker=0] No checkpointed highwatermark is found for partition connect-offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,449] INFO [Partition connect-offsets-0 broker=0] Log loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,456] INFO [LogLoader partition=connect-offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,456] INFO Created log for partition connect-offsets-19 in /tmp/kafka-logs/connect-offsets-19 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,456] INFO [Partition connect-offsets-19 broker=0] No checkpointed highwatermark is found for partition connect-offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:05:25,456] INFO [Partition connect-offsets-19 broker=0] Log loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,461] INFO [LogLoader partition=connect-offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,461] INFO Created log for partition connect-offsets-15 in /tmp/kafka-logs/connect-offsets-15 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,461] INFO [Partition connect-offsets-15 broker=0] No checkpointed highwatermark is found for partition connect-offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:05:25,461] INFO [Partition connect-offsets-15 broker=0] Log loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,467] INFO [LogLoader partition=connect-offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,467] INFO Created log for partition connect-offsets-10 in /tmp/kafka-logs/connect-offsets-10 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,467] INFO [Partition connect-offsets-10 broker=0] No checkpointed highwatermark is found for partition connect-offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:05:25,467] INFO [Partition connect-offsets-10 broker=0] Log loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,474] INFO [LogLoader partition=connect-offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,474] INFO Created log for partition connect-offsets-21 in /tmp/kafka-logs/connect-offsets-21 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,474] INFO [Partition connect-offsets-21 broker=0] No checkpointed highwatermark is found for partition connect-offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:05:25,474] INFO [Partition connect-offsets-21 broker=0] Log loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,481] INFO [LogLoader partition=connect-offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,481] INFO Created log for partition connect-offsets-6 in /tmp/kafka-logs/connect-offsets-6 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,481] INFO [Partition connect-offsets-6 broker=0] No checkpointed highwatermark is found for partition connect-offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:05:25,481] INFO [Partition connect-offsets-6 broker=0] Log loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,487] INFO [LogLoader partition=connect-offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,487] INFO Created log for partition connect-offsets-18 in /tmp/kafka-logs/connect-offsets-18 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,487] INFO [Partition connect-offsets-18 broker=0] No checkpointed highwatermark is found for partition connect-offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:05:25,487] INFO [Partition connect-offsets-18 broker=0] Log loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,495] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,495] INFO Created log for partition connect-offsets-3 in /tmp/kafka-logs/connect-offsets-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,495] INFO [Partition connect-offsets-3 broker=0] No checkpointed highwatermark is found for partition connect-offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:05:25,495] INFO [Partition connect-offsets-3 broker=0] Log loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,502] INFO [LogLoader partition=connect-offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,502] INFO Created log for partition connect-offsets-14 in /tmp/kafka-logs/connect-offsets-14 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,502] INFO [Partition connect-offsets-14 broker=0] No checkpointed highwatermark is found for partition connect-offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:05:25,502] INFO [Partition connect-offsets-14 broker=0] Log loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,573] INFO Creating topic connect-status with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:05:25,603] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-status-4, connect-status-3, connect-status-2, connect-status-0, connect-status-1) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:05:25,604] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,605] INFO Created log for partition connect-status-4 in /tmp/kafka-logs/connect-status-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,605] INFO [Partition connect-status-4 broker=0] No checkpointed highwatermark is found for partition connect-status-4 (kafka.cluster.Partition)
[2025-01-06 17:05:25,605] INFO [Partition connect-status-4 broker=0] Log loaded for partition connect-status-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,612] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,613] INFO Created log for partition connect-status-1 in /tmp/kafka-logs/connect-status-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,613] INFO [Partition connect-status-1 broker=0] No checkpointed highwatermark is found for partition connect-status-1 (kafka.cluster.Partition)
[2025-01-06 17:05:25,613] INFO [Partition connect-status-1 broker=0] Log loaded for partition connect-status-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,620] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,620] INFO Created log for partition connect-status-0 in /tmp/kafka-logs/connect-status-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,620] INFO [Partition connect-status-0 broker=0] No checkpointed highwatermark is found for partition connect-status-0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,620] INFO [Partition connect-status-0 broker=0] Log loaded for partition connect-status-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,626] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,626] INFO Created log for partition connect-status-3 in /tmp/kafka-logs/connect-status-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,626] INFO [Partition connect-status-3 broker=0] No checkpointed highwatermark is found for partition connect-status-3 (kafka.cluster.Partition)
[2025-01-06 17:05:25,626] INFO [Partition connect-status-3 broker=0] Log loaded for partition connect-status-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,631] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,631] INFO Created log for partition connect-status-2 in /tmp/kafka-logs/connect-status-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,631] INFO [Partition connect-status-2 broker=0] No checkpointed highwatermark is found for partition connect-status-2 (kafka.cluster.Partition)
[2025-01-06 17:05:25,631] INFO [Partition connect-status-2 broker=0] Log loaded for partition connect-status-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,657] INFO Creating topic connect-configs with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:05:25,676] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(connect-configs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:05:25,678] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,678] INFO Created log for partition connect-configs-0 in /tmp/kafka-logs/connect-configs-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:05:25,679] INFO [Partition connect-configs-0 broker=0] No checkpointed highwatermark is found for partition connect-configs-0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,679] INFO [Partition connect-configs-0 broker=0] Log loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,704] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:05:25,782] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:05:25,784] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,784] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,784] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:05:25,785] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,791] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,791] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,791] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:05:25,791] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,797] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,797] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,797] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-01-06 17:05:25,797] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,805] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,805] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,805] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:05:25,805] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,813] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,813] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,813] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-01-06 17:05:25,813] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,821] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,821] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,822] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-01-06 17:05:25,822] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,830] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,831] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,831] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:05:25,831] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,835] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,835] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,835] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-01-06 17:05:25,835] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,842] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,842] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,842] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:05:25,842] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,849] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,849] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,849] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:05:25,849] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,856] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,856] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,856] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-01-06 17:05:25,856] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,863] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,863] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,863] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-01-06 17:05:25,863] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,871] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,871] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,871] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-01-06 17:05:25,871] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,875] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,876] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,876] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:05:25,876] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,883] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,884] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,884] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:05:25,886] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,890] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,890] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,890] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-01-06 17:05:25,890] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,897] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,897] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,897] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-01-06 17:05:25,897] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,904] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,904] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,904] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:05:25,904] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,911] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,911] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,911] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:05:25,911] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,919] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,919] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,919] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:05:25,919] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,925] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,926] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,926] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-01-06 17:05:25,926] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,933] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,934] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,934] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-01-06 17:05:25,934] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,942] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,942] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,942] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-01-06 17:05:25,942] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,948] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,949] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,949] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:05:25,949] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,956] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,956] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,957] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-01-06 17:05:25,957] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,963] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,963] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,963] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-01-06 17:05:25,963] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,966] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,967] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,967] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:05:25,967] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,972] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,972] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,972] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:05:25,972] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,979] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,979] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,979] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-01-06 17:05:25,979] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,985] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,986] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,986] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-01-06 17:05:25,986] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,993] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,993] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,993] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:05:25,993] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:25,997] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:25,997] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:25,997] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:05:25,997] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,004] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,004] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,004] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-01-06 17:05:26,004] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,013] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,013] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,014] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:05:26,014] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,020] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,020] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,020] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-01-06 17:05:26,020] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,027] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,027] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,027] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:05:26,027] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,035] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,035] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,035] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-01-06 17:05:26,035] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,042] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,043] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,043] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,043] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,051] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,051] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,051] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-01-06 17:05:26,051] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,058] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,058] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,058] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:05:26,058] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,065] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,065] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,065] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:05:26,065] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,070] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,070] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,070] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-01-06 17:05:26,070] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,075] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,076] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,076] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-01-06 17:05:26,076] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,083] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,083] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,083] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:05:26,083] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,091] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,092] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,092] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:05:26,092] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,101] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,101] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,101] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-01-06 17:05:26,101] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,106] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,106] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,106] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:05:26,106] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,114] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,115] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,115] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-01-06 17:05:26,115] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,120] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,121] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,122] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:05:26,122] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,127] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:05:26,127] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:05:26,127] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-01-06 17:05:26,127] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:05:26,135] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,135] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,136] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,136] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,137] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,138] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,139] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,139] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,139] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,139] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,139] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:05:26,468] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-cluster in Empty state. Created a new member id connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,477] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 with group instance id None; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,479] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 1 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:05:26,494] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,023] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,024] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 2 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,027] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,041] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 2 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,042] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 3 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,043] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:06:00,193] INFO Creating topic db.history.internal with configuration {cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:00,216] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(db.history.internal-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:00,218] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:00,219] INFO Created log for partition db.history.internal-0 in /tmp/kafka-logs/db.history.internal-0 with properties {cleanup.policy=delete, retention.bytes=-1, retention.ms=9223372036854775807} (kafka.log.LogManager)
[2025-01-06 17:06:00,219] INFO [Partition db.history.internal-0 broker=0] No checkpointed highwatermark is found for partition db.history.internal-0 (kafka.cluster.Partition)
[2025-01-06 17:06:00,219] INFO [Partition db.history.internal-0 broker=0] Log loaded for partition db.history.internal-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,303] INFO Creating topic kafka.leafy_factory.factories with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:01,333] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.factories-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:01,337] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:01,338] INFO Created log for partition kafka.leafy_factory.factories-0 in /tmp/kafka-logs/kafka.leafy_factory.factories-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:01,338] INFO [Partition kafka.leafy_factory.factories-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.factories-0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,339] INFO [Partition kafka.leafy_factory.factories-0 broker=0] Log loaded for partition kafka.leafy_factory.factories-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,445] INFO Creating topic kafka.leafy_factory.machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:01,475] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:01,478] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:01,479] INFO Created log for partition kafka.leafy_factory.machines-0 in /tmp/kafka-logs/kafka.leafy_factory.machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:01,479] INFO [Partition kafka.leafy_factory.machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.machines-0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,480] INFO [Partition kafka.leafy_factory.machines-0 broker=0] Log loaded for partition kafka.leafy_factory.machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,589] INFO Creating topic kafka.leafy_factory.production_lines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:01,618] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.production_lines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:01,621] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:01,621] INFO Created log for partition kafka.leafy_factory.production_lines-0 in /tmp/kafka-logs/kafka.leafy_factory.production_lines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:01,622] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.production_lines-0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,622] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] Log loaded for partition kafka.leafy_factory.production_lines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,728] INFO Creating topic kafka.leafy_factory.products with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:01,759] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:01,761] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:01,762] INFO Created log for partition kafka.leafy_factory.products-0 in /tmp/kafka-logs/kafka.leafy_factory.products-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:01,762] INFO [Partition kafka.leafy_factory.products-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products-0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,762] INFO [Partition kafka.leafy_factory.products-0 broker=0] Log loaded for partition kafka.leafy_factory.products-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,859] INFO Creating topic kafka.leafy_factory.products_raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:01,889] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products_raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:01,892] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:01,892] INFO Created log for partition kafka.leafy_factory.products_raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:01,893] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products_raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,893] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.products_raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:01,993] INFO Creating topic kafka.leafy_factory.raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:02,024] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:02,027] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:02,028] INFO Created log for partition kafka.leafy_factory.raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:02,028] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:06:02,028] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:33,387] INFO Creating topic kafka.leafy_factory.work_orders with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:33,457] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.work_orders-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:33,460] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:33,461] INFO Created log for partition kafka.leafy_factory.work_orders-0 in /tmp/kafka-logs/kafka.leafy_factory.work_orders-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:33,461] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.work_orders-0 (kafka.cluster.Partition)
[2025-01-06 17:06:33,461] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] Log loaded for partition kafka.leafy_factory.work_orders-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:06:33,556] INFO Creating topic kafka.leafy_factory.product_cost with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:06:33,582] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.product_cost-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:06:33,586] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:06:33,586] INFO Created log for partition kafka.leafy_factory.product_cost-0 in /tmp/kafka-logs/kafka.leafy_factory.product_cost-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:06:33,587] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.product_cost-0 (kafka.cluster.Partition)
[2025-01-06 17:06:33,587] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] Log loaded for partition kafka.leafy_factory.product_cost-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:07:56,309] INFO Creating topic kafka.leafy_factory.jobs with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:07:56,375] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:07:56,385] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:07:56,387] INFO Created log for partition kafka.leafy_factory.jobs-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:07:56,389] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs-0 (kafka.cluster.Partition)
[2025-01-06 17:07:56,389] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:07:56,460] INFO Creating topic kafka.leafy_factory.jobs_machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:07:56,486] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs_machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:07:56,488] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:07:56,488] INFO Created log for partition kafka.leafy_factory.jobs_machines-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs_machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:07:56,489] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs_machines-0 (kafka.cluster.Partition)
[2025-01-06 17:07:56,489] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs_machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:08:26,267] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 3 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,268] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 4 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,270] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,290] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 4 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,290] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 5 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,291] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,347] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-mongodb-sink in Empty state. Created a new member id connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,348] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924 with group instance id None; client reason: need to re-join with the given member-id: connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,352] INFO [GroupCoordinator 0]: Stabilized group connect-mongodb-sink generation 1 (__consumer_offsets-33) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:26,357] INFO [GroupCoordinator 0]: Assignment received from leader connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924 for group connect-mongodb-sink for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,368] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 5 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,369] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 6 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,372] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 6. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,474] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink in state PreparingRebalance with old generation 1 (__consumer_offsets-33) (reason: Removing member connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924 on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,474] INFO [GroupCoordinator 0]: Group connect-mongodb-sink with generation 2 is now empty (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,475] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=connector-consumer-mongodb-sink-0-fefe8c31-aaee-47fe-9b52-0114d192f924, groupInstanceId=None, clientId=connector-consumer-mongodb-sink-0, clientHost=/192.168.1.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group connect-mongodb-sink through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,487] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 6 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,487] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 7 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:08:39,489] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,770] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 7 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,770] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 8 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,773] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 8. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,793] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 8 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,794] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 9 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,795] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-d4d7dfc6-187b-4215-9166-b25f55dd1ac9 for group connect-cluster for generation 9. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,849] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-mongodb-sink-connector in Empty state. Created a new member id connector-consumer-mongodb-sink-connector-0-e553ccd2-f9fd-4a4f-8c1c-ec834750d683 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,851] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink-connector in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member connector-consumer-mongodb-sink-connector-0-e553ccd2-f9fd-4a4f-8c1c-ec834750d683 with group instance id None; client reason: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-e553ccd2-f9fd-4a4f-8c1c-ec834750d683) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,852] INFO [GroupCoordinator 0]: Stabilized group connect-mongodb-sink-connector generation 1 (__consumer_offsets-33) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:10:14,854] INFO [GroupCoordinator 0]: Assignment received from leader connector-consumer-mongodb-sink-connector-0-e553ccd2-f9fd-4a4f-8c1c-ec834750d683 for group connect-mongodb-sink-connector for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:28:57,605] WARN Session 0x10006ac1c3f0000 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10006ac1c3f0000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:28:58,773] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:28:58,775] WARN Session 0x10006ac1c3f0000 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:28:59,589] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:28:59,593] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:28:59,595] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-06 17:28:59,612] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2025-01-06 17:28:59,615] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:28:59,616] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:28:59,616] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:28:59,616] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:28:59,622] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:28:59,622] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:28:59,623] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:28:59,625] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,626] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,626] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,628] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-06 17:28:59,628] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,629] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,629] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,630] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:28:59,631] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-06 17:28:59,631] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:28:59,631] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:28:59,631] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:28:59,632] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:28:59,632] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:28:59,633] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,633] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,633] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,634] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,634] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,634] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,635] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:28:59,635] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-06 17:28:59,635] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:28:59,635] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:28:59,635] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:28:59,635] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:28:59,636] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:28:59,637] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:28:59,637] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:28:59,637] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,637] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,637] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,638] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,639] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,639] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,639] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,639] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,639] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:28:59,646] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:28:59,646] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:28:59,646] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:28:59,646] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-06 17:28:59,646] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,647] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,647] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,647] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:28:59,647] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,648] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,648] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:28:59,648] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:28:59,648] INFO Shutting down. (kafka.log.LogManager)
[2025-01-06 17:28:59,649] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:28:59,649] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:28:59,649] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:28:59,708] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs_machines-0] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,732] INFO [ProducerStateManager partition=connect-status-4] Wrote producer snapshot at offset 26 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,754] INFO [ProducerStateManager partition=connect-offsets-3] Wrote producer snapshot at offset 8 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,788] INFO [ProducerStateManager partition=connect-status-0] Wrote producer snapshot at offset 24 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,795] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:28:59,804] INFO [ProducerStateManager partition=db.history.internal-0] Wrote producer snapshot at offset 24 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,818] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs-0] Wrote producer snapshot at offset 2 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,832] INFO [ProducerStateManager partition=connect-configs-0] Wrote producer snapshot at offset 12 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,866] INFO [ProducerStateManager partition=connect-status-2] Wrote producer snapshot at offset 15 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,887] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 9 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,912] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 43 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,919] INFO [ProducerStateManager partition=kafka.leafy_factory.factories-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,940] INFO [ProducerStateManager partition=connect-status-1] Wrote producer snapshot at offset 53 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,973] INFO [ProducerStateManager partition=connect-status-3] Wrote producer snapshot at offset 22 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:28:59,980] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:28:59,994] INFO [ProducerStateManager partition=kafka.leafy_factory.machines-0] Wrote producer snapshot at offset 6 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,003] INFO [ProducerStateManager partition=kafka.leafy_factory.production_lines-0] Wrote producer snapshot at offset 2 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,015] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:29:00,016] INFO [ProducerStateManager partition=kafka.leafy_factory.work_orders-0] Wrote producer snapshot at offset 10 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,016] WARN Session 0x10006ac1c3f0000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:29:00,041] INFO [ProducerStateManager partition=kafka.leafy_factory.product_cost-0] Wrote producer snapshot at offset 7 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,058] INFO [ProducerStateManager partition=kafka.leafy_factory.raw_materials-0] Wrote producer snapshot at offset 36 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,076] INFO [ProducerStateManager partition=kafka.leafy_factory.products-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,096] INFO [ProducerStateManager partition=kafka.leafy_factory.products_raw_materials-0] Wrote producer snapshot at offset 8 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:29:00,135] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-06 17:29:00,139] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:29:00,139] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:29:00,139] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:29:00,139] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:29:01,933] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:29:02,041] INFO Session: 0x10006ac1c3f0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:29:02,041] INFO EventThread shut down for session: 0x10006ac1c3f0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:29:02,043] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:29:02,044] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,046] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,046] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,046] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,046] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,046] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,047] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:29:02,048] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-06 17:29:02,062] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-06 17:29:02,063] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:29:02,063] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:29:02,063] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:29:02,063] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-06 17:29:02,064] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:29:02,064] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-06 17:30:36,654] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,655] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,656] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,656] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,657] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,657] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,657] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:30:36,657] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:30:36,657] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:30:36,657] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-06 17:30:36,658] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-06 17:30:36,658] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:30:36,658] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-06 17:30:36,663] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9225652 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-06 17:30:36,664] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:30:36,664] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:30:36,666] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:30:36,670] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,670] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,683] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:host.name=192.168.1.5 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:os.arch=aarch64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,684] INFO Server environment:os.version=15.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:user.name=gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,685] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-06 17:30:36,686] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,686] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,686] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:30:36,686] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,687] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:30:36,688] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,688] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,689] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:30:36,689] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:30:36,689] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,692] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:30:36,692] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:30:36,693] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 22 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:30:36,697] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:30:36,706] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:30:36,706] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:30:36,706] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:30:36,706] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:30:36,708] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-06 17:30:36,708] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2025-01-06 17:30:36,710] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2025-01-06 17:30:36,729] INFO 273 txns loaded in 18 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:30:36,729] INFO Snapshot loaded in 23 ms, highest zxid is 0x111, digest is 523468752170 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:30:36,730] INFO Snapshotting: 0x111 to /tmp/zookeeper/version-2/snapshot.111 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:30:36,732] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:30:36,735] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-06 17:30:36,735] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-06 17:30:36,741] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-06 17:30:36,742] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-06 17:30:40,280] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-06 17:30:40,383] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-06 17:30:40,422] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:30:40,423] INFO starting (kafka.server.KafkaServer)
[2025-01-06 17:30:40,423] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-06 17:30:40,433] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:40,437] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,437] INFO Client environment:host.name=192.168.1.5 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,437] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.arch=aarch64 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.version=15.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:user.name=gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,438] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,439] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e403b4a (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:40,442] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-06 17:30:40,445] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:40,446] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:40,446] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:40,448] INFO Socket connection established, initiating session, client: /127.0.0.1:50211, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:40,451] INFO Creating new log file: log.112 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-06 17:30:40,459] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10006c4a83d0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:40,460] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:40,581] INFO Cluster ID = ENYvlSzpQfichNYMko35Tg (kafka.server.KafkaServer)
[2025-01-06 17:30:40,601] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-06 17:30:40,616] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:40,616] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:40,616] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:40,617] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:40,643] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,652] INFO Skipping recovery of 92 logs from /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-06 17:30:40,687] INFO [LogLoader partition=connect-offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,694] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-21, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 39ms (1/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,698] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,698] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,698] INFO [ProducerStateManager partition=db.history.internal-0] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=/tmp/kafka-logs/db.history.internal-0/00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,702] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,703] INFO Completed load of Log(dir=/tmp/kafka-logs/db.history.internal-0, topicId=Dlhs_wEtRzKcHBgkHqfP7g, topic=db.history.internal, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 8ms (2/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,707] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,708] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (3/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,710] INFO [LogLoader partition=connect-offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,710] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-19, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (4/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,715] INFO [LogLoader partition=connect-offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,715] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-10, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (5/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,720] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,721] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-0, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (6/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,723] INFO [LogLoader partition=connect-offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,724] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-17, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (7/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,727] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,727] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-7, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (8/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,732] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,732] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-31, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (9/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,734] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,734] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-36, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (10/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,739] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,739] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 26 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,739] INFO [ProducerStateManager partition=connect-status-4] Loading producer state from snapshot file 'SnapshotFile(offset=26, file=/tmp/kafka-logs/connect-status-4/00000000000000000026.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,739] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 26 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,740] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-4, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=26) with 1 segments, local-log-start-offset 0 and log-end-offset 26 in 5ms (11/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,744] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,744] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-38, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (12/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,747] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Loading producer state till offset 22 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,747] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 22 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,747] INFO [ProducerStateManager partition=connect-status-3] Loading producer state from snapshot file 'SnapshotFile(offset=22, file=/tmp/kafka-logs/connect-status-3/00000000000000000022.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,747] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 22 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,748] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-3, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=22) with 1 segments, local-log-start-offset 0 and log-end-offset 22 in 3ms (13/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,751] INFO [LogLoader partition=connect-offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,752] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-16, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (14/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,754] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,755] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-6, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (15/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,758] INFO [LogLoader partition=connect-offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,759] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-11, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (16/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,762] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,763] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,763] INFO [ProducerStateManager partition=kafka.leafy_factory.machines-0] Loading producer state from snapshot file 'SnapshotFile(offset=6, file=/tmp/kafka-logs/kafka.leafy_factory.machines-0/00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,763] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,763] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.machines-0, topicId=GRGIX_vMTQq3_zKACtehQw, topic=kafka.leafy_factory.machines, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 4ms (17/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,766] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,767] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-1, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (18/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,771] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,771] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-8, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (19/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,775] INFO [LogLoader partition=connect-offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,776] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-18, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (20/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,778] INFO [LogLoader partition=connect-offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,779] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-20, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (21/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,783] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,783] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 15 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,783] INFO [ProducerStateManager partition=connect-status-2] Loading producer state from snapshot file 'SnapshotFile(offset=15, file=/tmp/kafka-logs/connect-status-2/00000000000000000015.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,783] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 15 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,784] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-2, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=15) with 1 segments, local-log-start-offset 0 and log-end-offset 15 in 4ms (22/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,787] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,788] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (23/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,790] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,790] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-37, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (24/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,793] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,794] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-30, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (25/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,797] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,797] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,797] INFO [ProducerStateManager partition=kafka.leafy_factory.products-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/kafka.leafy_factory.products-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,797] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,801] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.products-0, topicId=QAMzDFDtS0GR31i-mijF7A, topic=kafka.leafy_factory.products, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 7ms (26/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,802] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,802] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,803] INFO [ProducerStateManager partition=kafka.leafy_factory.products_raw_materials-0] Loading producer state from snapshot file 'SnapshotFile(offset=8, file=/tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0/00000000000000000008.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,803] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,803] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0, topicId=HO1EEskbTT2nt7zQAQaLSQ, topic=kafka.leafy_factory.products_raw_materials, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=8) with 1 segments, local-log-start-offset 0 and log-end-offset 8 in 2ms (27/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,808] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,808] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,808] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/kafka.leafy_factory.jobs-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,808] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,809] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.jobs-0, topicId=I20H0WygQAan0HUrFj-MJA, topic=kafka.leafy_factory.jobs, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 2ms (28/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,811] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,811] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-12, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (29/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,813] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,813] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (30/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,816] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,817] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (31/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,819] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,819] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-24, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (32/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,822] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,823] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-48, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (33/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,825] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Loading producer state till offset 10 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,826] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 10 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,826] INFO [ProducerStateManager partition=kafka.leafy_factory.work_orders-0] Loading producer state from snapshot file 'SnapshotFile(offset=10, file=/tmp/kafka-logs/kafka.leafy_factory.work_orders-0/00000000000000000010.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,826] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 10 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,826] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.work_orders-0, topicId=jxEnnjt5QfK7tVX_jQkHLg, topic=kafka.leafy_factory.work_orders, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=10) with 1 segments, local-log-start-offset 0 and log-end-offset 10 in 3ms (34/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,830] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,831] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (35/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,833] INFO [LogLoader partition=connect-offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,834] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-4, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (36/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,835] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,836] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (37/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,840] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,840] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,840] INFO [ProducerStateManager partition=connect-offsets-3] Loading producer state from snapshot file 'SnapshotFile(offset=8, file=/tmp/kafka-logs/connect-offsets-3/00000000000000000008.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,840] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,841] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-3, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=8) with 1 segments, local-log-start-offset 0 and log-end-offset 8 in 3ms (38/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,844] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,845] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-25, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (39/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,847] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,848] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (40/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,851] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,852] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-14, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (41/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,855] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,855] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 9 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,855] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(offset=9, file=/tmp/kafka-logs/__consumer_offsets-13/00000000000000000009.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,855] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 9 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,855] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-13, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=9) with 1 segments, local-log-start-offset 0 and log-end-offset 9 in 3ms (42/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,859] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,859] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (43/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,862] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,863] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,863] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs_machines-0] Loading producer state from snapshot file 'SnapshotFile(offset=4, file=/tmp/kafka-logs/kafka.leafy_factory.jobs_machines-0/00000000000000000004.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,863] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,863] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.jobs_machines-0, topicId=Ag4RePNFSEennllRyrmkxg, topic=kafka.leafy_factory.jobs_machines, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments, local-log-start-offset 0 and log-end-offset 4 in 4ms (44/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,866] INFO [LogLoader partition=connect-offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,866] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-2, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (45/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,868] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,869] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (46/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,871] INFO [LogLoader partition=connect-offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,872] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-5, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (47/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,874] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,875] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-49, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (48/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,878] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,879] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (49/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,881] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,882] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-32, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (50/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,884] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,884] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,884] INFO [ProducerStateManager partition=connect-status-0] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=/tmp/kafka-logs/connect-status-0/00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,885] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,885] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-0, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 3ms (51/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,888] INFO [LogLoader partition=connect-offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,888] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-22, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (52/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,890] INFO [LogLoader partition=connect-offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,890] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-14, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (53/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,893] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,894] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (54/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,896] INFO [LogLoader partition=connect-offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,896] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-13, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (55/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,899] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,900] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (56/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,902] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Loading producer state till offset 53 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,902] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 53 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,902] INFO [ProducerStateManager partition=connect-status-1] Loading producer state from snapshot file 'SnapshotFile(offset=53, file=/tmp/kafka-logs/connect-status-1/00000000000000000053.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,902] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 53 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,903] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-1, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=53) with 1 segments, local-log-start-offset 0 and log-end-offset 53 in 2ms (57/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,906] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 43 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,906] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 43 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,906] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(offset=43, file=/tmp/kafka-logs/__consumer_offsets-33/00000000000000000043.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,906] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 43 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,907] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=43) with 1 segments, local-log-start-offset 0 and log-end-offset 43 in 2ms (58/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,909] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,910] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (59/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,912] INFO [LogLoader partition=connect-offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,913] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-12, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (60/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,915] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,915] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-2, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (61/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,918] INFO [LogLoader partition=connect-offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,919] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-15, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (62/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,921] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 36 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,921] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 36 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,921] INFO [ProducerStateManager partition=kafka.leafy_factory.raw_materials-0] Loading producer state from snapshot file 'SnapshotFile(offset=36, file=/tmp/kafka-logs/kafka.leafy_factory.raw_materials-0/00000000000000000036.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,922] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 36 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,922] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.raw_materials-0, topicId=HhZPCRKARVymJPez8Bdlow, topic=kafka.leafy_factory.raw_materials, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=36) with 1 segments, local-log-start-offset 0 and log-end-offset 36 in 3ms (63/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,925] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,926] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (64/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,929] INFO [LogLoader partition=connect-offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,929] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-23, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (65/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,932] INFO [LogLoader partition=connect-offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,933] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-24, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (66/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,936] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,936] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 12 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,936] INFO [ProducerStateManager partition=connect-configs-0] Loading producer state from snapshot file 'SnapshotFile(offset=12, file=/tmp/kafka-logs/connect-configs-0/00000000000000000012.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,937] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 12 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,937] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-configs-0, topicId=aSX1wv19RViLjKu8TYFR-A, topic=connect-configs, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=12) with 1 segments, local-log-start-offset 0 and log-end-offset 12 in 4ms (67/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,940] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,940] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,940] INFO [ProducerStateManager partition=kafka.leafy_factory.factories-0] Loading producer state from snapshot file 'SnapshotFile(offset=1, file=/tmp/kafka-logs/kafka.leafy_factory.factories-0/00000000000000000001.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,941] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,942] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.factories-0, topicId=jIyFXwnzQyK0GPWMWmSpMg, topic=kafka.leafy_factory.factories, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments, local-log-start-offset 0 and log-end-offset 1 in 2ms (68/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,944] INFO [LogLoader partition=connect-offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,945] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-9, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (69/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,947] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,947] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,947] INFO [ProducerStateManager partition=kafka.leafy_factory.production_lines-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/kafka.leafy_factory.production_lines-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,948] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,948] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.production_lines-0, topicId=v7T3YlOMS4a2qEfWBqPFVw, topic=kafka.leafy_factory.production_lines, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 3ms (70/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,951] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,951] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,951] INFO [ProducerStateManager partition=kafka.leafy_factory.product_cost-0] Loading producer state from snapshot file 'SnapshotFile(offset=7, file=/tmp/kafka-logs/kafka.leafy_factory.product_cost-0/00000000000000000007.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:40,951] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,952] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.product_cost-0, topicId=E7WnENIBTnKOj7K5QWIRVg, topic=kafka.leafy_factory.product_cost, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments, local-log-start-offset 0 and log-end-offset 7 in 2ms (71/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,954] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,954] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (72/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,957] INFO [LogLoader partition=connect-offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,958] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-0, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (73/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,960] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,961] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-42, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (74/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,963] INFO [LogLoader partition=connect-offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,964] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-7, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (75/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,965] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,966] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (76/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,968] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,969] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (77/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,971] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,972] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (78/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,974] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,975] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-18, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (79/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,977] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,978] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (80/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,981] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,982] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-20, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (81/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,984] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,985] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-43, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (82/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,987] INFO [LogLoader partition=connect-offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,988] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-6, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (83/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,990] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,991] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-44, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (84/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,992] INFO [LogLoader partition=connect-offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,993] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-1, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (85/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,995] INFO [LogLoader partition=connect-offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,996] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-8, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (86/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:40,998] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:40,999] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (87/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,001] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:41,002] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-19, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (88/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,004] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:41,005] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-26, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (89/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,007] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:41,008] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (90/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,010] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:41,011] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (91/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,014] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:41,014] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (92/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:41,015] INFO Loaded 92 logs in 372ms (kafka.log.LogManager)
[2025-01-06 17:30:41,018] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-06 17:30:41,018] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-06 17:30:41,044] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:30:41,051] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:30:41,059] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-06 17:30:41,069] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,175] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-06 17:30:41,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-06 17:30:41,182] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,191] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,191] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,191] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,191] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,192] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,196] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:30:41,196] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:30:41,213] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-06 17:30:41,223] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x10006ac1c3f0000' does not match current session '0x10006c4a83d0000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2025-01-06 17:30:41,224] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-06 17:30:41,225] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:30:41,226] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:30:41,226] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-06 17:30:41,228] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:30:41,229] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-06 17:30:41,229] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:30:41,229] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:30:41,229] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:30:41,229] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:30:41,229] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:30:41,229] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:30:41,230] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,230] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,231] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,231] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,231] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,231] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,231] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:30:41,233] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:30:41,233] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:30:41,233] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:30:41,233] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-06 17:30:41,233] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,233] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,233] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,234] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:30:41,234] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,234] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,234] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:30:41,234] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:30:41,234] INFO Shutting down. (kafka.log.LogManager)
[2025-01-06 17:30:41,234] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:30:41,235] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:30:41,235] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:30:41,539] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-06 17:30:41,542] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:30:41,542] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:30:41,542] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:30:41,542] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:41,657] INFO Session: 0x10006c4a83d0000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:41,657] INFO EventThread shut down for session: 0x10006c4a83d0000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:41,659] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:41,659] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,660] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,660] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,660] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,661] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:41,662] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-06 17:30:41,675] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-06 17:30:41,676] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:30:41,676] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:30:41,677] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-06 17:30:41,681] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:30:41,681] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-06 17:30:41,681] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2025-01-06 17:30:41,682] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:30:55,078] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-06 17:30:55,169] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-06 17:30:55,211] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:30:55,212] INFO starting (kafka.server.KafkaServer)
[2025-01-06 17:30:55,212] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-06 17:30:55,223] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:55,237] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,237] INFO Client environment:host.name=192.168.1.5 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,237] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,237] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,237] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,237] INFO Client environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.arch=aarch64 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.version=15.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:user.name=gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,238] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,239] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e403b4a (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:30:55,242] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-06 17:30:55,245] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:55,246] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:55,246] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:55,248] INFO Socket connection established, initiating session, client: /127.0.0.1:50221, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:55,254] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10006c4a83d0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:30:55,255] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:30:55,374] INFO Cluster ID = ENYvlSzpQfichNYMko35Tg (kafka.server.KafkaServer)
[2025-01-06 17:30:55,393] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-06 17:30:55,407] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:55,407] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:55,407] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:55,408] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:30:55,430] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,438] INFO Skipping recovery of 92 logs from /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2025-01-06 17:30:55,467] INFO [LogLoader partition=connect-offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,472] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-21, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 32ms (1/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,476] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Loading producer state till offset 24 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,476] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,476] INFO [ProducerStateManager partition=db.history.internal-0] Loading producer state from snapshot file 'SnapshotFile(offset=24, file=/tmp/kafka-logs/db.history.internal-0/00000000000000000024.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,479] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 24 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,481] INFO Completed load of Log(dir=/tmp/kafka-logs/db.history.internal-0, topicId=Dlhs_wEtRzKcHBgkHqfP7g, topic=db.history.internal, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=24) with 1 segments, local-log-start-offset 0 and log-end-offset 24 in 9ms (2/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,482] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,483] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (3/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,484] INFO [LogLoader partition=connect-offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,485] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-19, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (4/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,486] INFO [LogLoader partition=connect-offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,487] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-10, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (5/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,488] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,489] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-0, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (6/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,490] INFO [LogLoader partition=connect-offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,490] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-17, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (7/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,492] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,492] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-7, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (8/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,493] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,494] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-31, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (9/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,496] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,496] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-36, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (10/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,498] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Loading producer state till offset 26 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,498] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 26 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,498] INFO [ProducerStateManager partition=connect-status-4] Loading producer state from snapshot file 'SnapshotFile(offset=26, file=/tmp/kafka-logs/connect-status-4/00000000000000000026.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,498] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 26 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,499] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-4, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=26) with 1 segments, local-log-start-offset 0 and log-end-offset 26 in 3ms (11/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,501] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,502] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-38, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 3ms (12/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,504] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Loading producer state till offset 22 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,504] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 22 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,504] INFO [ProducerStateManager partition=connect-status-3] Loading producer state from snapshot file 'SnapshotFile(offset=22, file=/tmp/kafka-logs/connect-status-3/00000000000000000022.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,504] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 22 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,505] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-3, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=22) with 1 segments, local-log-start-offset 0 and log-end-offset 22 in 3ms (13/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,508] INFO [LogLoader partition=connect-offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,509] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-16, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (14/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,510] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,510] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-6, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (15/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,511] INFO [LogLoader partition=connect-offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,512] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-11, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (16/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,513] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,513] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,513] INFO [ProducerStateManager partition=kafka.leafy_factory.machines-0] Loading producer state from snapshot file 'SnapshotFile(offset=6, file=/tmp/kafka-logs/kafka.leafy_factory.machines-0/00000000000000000006.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,513] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,514] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.machines-0, topicId=GRGIX_vMTQq3_zKACtehQw, topic=kafka.leafy_factory.machines, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments, local-log-start-offset 0 and log-end-offset 6 in 2ms (17/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,517] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,518] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-1, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (18/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,519] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,519] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-8, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (19/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,520] INFO [LogLoader partition=connect-offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,520] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-18, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (20/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,521] INFO [LogLoader partition=connect-offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,522] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-offsets-20, topicId=LzEYqqZ7S5S_BwOHRpTleA, topic=connect-offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (21/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,523] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,523] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 15 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,523] INFO [ProducerStateManager partition=connect-status-2] Loading producer state from snapshot file 'SnapshotFile(offset=15, file=/tmp/kafka-logs/connect-status-2/00000000000000000015.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,523] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 15 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,524] INFO Completed load of Log(dir=/tmp/kafka-logs/connect-status-2, topicId=H8XWtOBfRcWBf8RO-iah8A, topic=connect-status, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=15) with 1 segments, local-log-start-offset 0 and log-end-offset 15 in 2ms (22/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,527] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,528] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (23/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,529] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,529] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-37, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (24/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,530] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,531] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-30, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 1ms (25/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,533] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,533] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,533] INFO [ProducerStateManager partition=kafka.leafy_factory.products-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/kafka.leafy_factory.products-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,533] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,534] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.products-0, topicId=QAMzDFDtS0GR31i-mijF7A, topic=kafka.leafy_factory.products, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 3ms (26/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,539] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,539] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,539] INFO [ProducerStateManager partition=kafka.leafy_factory.products_raw_materials-0] Loading producer state from snapshot file 'SnapshotFile(offset=8, file=/tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0/00000000000000000008.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,539] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 8 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,540] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0, topicId=HO1EEskbTT2nt7zQAQaLSQ, topic=kafka.leafy_factory.products_raw_materials, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=8) with 1 segments, local-log-start-offset 0 and log-end-offset 8 in 4ms (27/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,543] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,543] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,543] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs-0] Loading producer state from snapshot file 'SnapshotFile(offset=2, file=/tmp/kafka-logs/kafka.leafy_factory.jobs-0/00000000000000000002.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:30:55,543] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,544] INFO Completed load of Log(dir=/tmp/kafka-logs/kafka.leafy_factory.jobs-0, topicId=I20H0WygQAan0HUrFj-MJA, topic=kafka.leafy_factory.jobs, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments, local-log-start-offset 0 and log-end-offset 2 in 2ms (28/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,547] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:30:55,547] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,548] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-12, topicId=FOfm9EHqTbiDAKrzCe1BzA, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 2ms (29/92 completed in /tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:30:55,549] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:30:55,550] ERROR [KafkaServer id=0] Fatal error during KafkaServer shutdown. (kafka.server.KafkaServer)
java.lang.IllegalStateException: Kafka server is still starting up, cannot shut down!
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:982)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.Kafka$.$anonfun$main$3(Kafka.scala:103)
	at kafka.utils.Exit$.$anonfun$addShutdownHook$1(Exit.scala:38)
	at java.base/java.lang.Thread.run(Thread.java:1575)
[2025-01-06 17:30:55,551] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:30:55,551] ERROR Halting Kafka. (kafka.Kafka$)
[2025-01-06 17:30:55,936] INFO Unable to read additional data from client, it probably closed the socket: address = /127.0.0.1:50221, session = 0x10006c4a83d0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2025-01-06 17:30:56,312] INFO Expiring session 0x10006ac1c3f0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,309] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,310] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,311] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,311] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,311] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,311] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,312] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:31:12,312] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:31:12,312] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:31:12,312] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-06 17:31:12,313] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-06 17:31:12,313] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:31:12,313] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-06 17:31:12,318] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9225652 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-06 17:31:12,319] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:31:12,319] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:31:12,320] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:31:12,324] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,324] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:host.name=192.168.1.5 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,336] INFO Server environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.arch=aarch64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.version=15.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:user.name=gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,337] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,338] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,338] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,338] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,338] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,338] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,339] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-06 17:31:12,340] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,340] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,340] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:31:12,340] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,341] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:31:12,342] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,342] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,342] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:31:12,342] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:31:12,342] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,345] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:31:12,345] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:31:12,346] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 22 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:31:12,349] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:31:12,357] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:31:12,358] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:31:12,358] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:31:12,358] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:31:12,360] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-06 17:31:12,360] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:31:12,365] INFO Snapshot loaded in 7 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:31:12,366] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:31:12,366] INFO Snapshot taken in 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:31:12,371] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-06 17:31:12,371] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-06 17:31:12,377] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-06 17:31:12,378] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-06 17:31:20,221] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-06 17:31:20,313] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-06 17:31:20,350] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:31:20,351] INFO starting (kafka.server.KafkaServer)
[2025-01-06 17:31:20,351] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-06 17:31:20,361] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:31:20,364] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,364] INFO Client environment:host.name=192.168.1.5 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,364] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,364] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,364] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.arch=aarch64 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.version=15.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:user.name=gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,365] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,366] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e403b4a (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:31:20,369] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-06 17:31:20,371] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:31:20,372] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:31:20,372] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:31:20,374] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:50232, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:31:20,378] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-06 17:31:20,386] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10006c533700000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:31:20,389] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:31:20,557] INFO Cluster ID = Gz1ZzhDTQK2atwk4SntaoA (kafka.server.KafkaServer)
[2025-01-06 17:31:20,575] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-06 17:31:20,588] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:31:20,588] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:31:20,588] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:31:20,589] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:31:20,591] INFO [KafkaServer id=0] Rewriting /tmp/kafka-logs/meta.properties (kafka.server.KafkaServer)
[2025-01-06 17:31:20,611] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:31:20,613] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
[2025-01-06 17:31:20,617] INFO Loaded 0 logs in 5ms (kafka.log.LogManager)
[2025-01-06 17:31:20,617] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-06 17:31:20,617] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-06 17:31:20,661] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:31:20,668] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:31:20,672] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:31:20,681] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:31:20,795] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-06 17:31:20,802] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-06 17:31:20,804] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:31:20,815] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,816] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,816] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,816] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,816] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,821] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:31:20,821] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:31:20,829] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-06 17:31:20,840] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1736206280834,1736206280834,1,0,0,72065038079229952,206,0,25
 (kafka.zk.KafkaZkClient)
[2025-01-06 17:31:20,840] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.1.5:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2025-01-06 17:31:20,857] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,860] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,860] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,862] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2025-01-06 17:31:20,868] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:20,870] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:31:20,871] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:20,881] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:31:20,883] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:31:20,884] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:31:20,884] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-06 17:31:20,905] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:31:20,910] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:31:20,911] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:31:20,912] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:31:20,918] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:31:20,921] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-06 17:31:20,922] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-06 17:31:20,925] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:31:20,925] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:31:20,925] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:31:20,925] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:31:20,927] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:31:20,927] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:31:20,927] INFO Kafka startTimeMs: 1736206280925 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:31:20,927] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-06 17:31:21,087] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:31:21,107] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:31:33,511] INFO Creating topic connect-offsets with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:31:33,625] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-offsets-20, connect-offsets-6, connect-offsets-17, connect-offsets-15, connect-offsets-7, connect-offsets-24, connect-offsets-16, connect-offsets-3, connect-offsets-21, connect-offsets-11, connect-offsets-10, connect-offsets-2, connect-offsets-18, connect-offsets-23, connect-offsets-4, connect-offsets-12, connect-offsets-5, connect-offsets-13, connect-offsets-14, connect-offsets-0, connect-offsets-8, connect-offsets-9, connect-offsets-1, connect-offsets-19, connect-offsets-22) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:31:33,648] INFO [LogLoader partition=connect-offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,652] INFO Created log for partition connect-offsets-24 in /tmp/kafka-logs/connect-offsets-24 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,653] INFO [Partition connect-offsets-24 broker=0] No checkpointed highwatermark is found for partition connect-offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:31:33,654] INFO [Partition connect-offsets-24 broker=0] Log loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,665] INFO [LogLoader partition=connect-offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,666] INFO Created log for partition connect-offsets-9 in /tmp/kafka-logs/connect-offsets-9 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,666] INFO [Partition connect-offsets-9 broker=0] No checkpointed highwatermark is found for partition connect-offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:31:33,666] INFO [Partition connect-offsets-9 broker=0] Log loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,676] INFO [LogLoader partition=connect-offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,676] INFO Created log for partition connect-offsets-20 in /tmp/kafka-logs/connect-offsets-20 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,677] INFO [Partition connect-offsets-20 broker=0] No checkpointed highwatermark is found for partition connect-offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:31:33,677] INFO [Partition connect-offsets-20 broker=0] Log loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,685] INFO [LogLoader partition=connect-offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,685] INFO Created log for partition connect-offsets-5 in /tmp/kafka-logs/connect-offsets-5 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,685] INFO [Partition connect-offsets-5 broker=0] No checkpointed highwatermark is found for partition connect-offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:31:33,686] INFO [Partition connect-offsets-5 broker=0] Log loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,694] INFO [LogLoader partition=connect-offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,695] INFO Created log for partition connect-offsets-17 in /tmp/kafka-logs/connect-offsets-17 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,695] INFO [Partition connect-offsets-17 broker=0] No checkpointed highwatermark is found for partition connect-offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:31:33,695] INFO [Partition connect-offsets-17 broker=0] Log loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,703] INFO [LogLoader partition=connect-offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,704] INFO Created log for partition connect-offsets-2 in /tmp/kafka-logs/connect-offsets-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,704] INFO [Partition connect-offsets-2 broker=0] No checkpointed highwatermark is found for partition connect-offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:31:33,704] INFO [Partition connect-offsets-2 broker=0] Log loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,713] INFO [LogLoader partition=connect-offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,713] INFO Created log for partition connect-offsets-13 in /tmp/kafka-logs/connect-offsets-13 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,713] INFO [Partition connect-offsets-13 broker=0] No checkpointed highwatermark is found for partition connect-offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:31:33,713] INFO [Partition connect-offsets-13 broker=0] Log loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,720] INFO [LogLoader partition=connect-offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,720] INFO Created log for partition connect-offsets-8 in /tmp/kafka-logs/connect-offsets-8 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,720] INFO [Partition connect-offsets-8 broker=0] No checkpointed highwatermark is found for partition connect-offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:31:33,720] INFO [Partition connect-offsets-8 broker=0] Log loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,728] INFO [LogLoader partition=connect-offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,728] INFO Created log for partition connect-offsets-4 in /tmp/kafka-logs/connect-offsets-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,728] INFO [Partition connect-offsets-4 broker=0] No checkpointed highwatermark is found for partition connect-offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:31:33,728] INFO [Partition connect-offsets-4 broker=0] Log loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,737] INFO [LogLoader partition=connect-offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,737] INFO Created log for partition connect-offsets-23 in /tmp/kafka-logs/connect-offsets-23 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,737] INFO [Partition connect-offsets-23 broker=0] No checkpointed highwatermark is found for partition connect-offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:31:33,737] INFO [Partition connect-offsets-23 broker=0] Log loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,743] INFO [LogLoader partition=connect-offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,744] INFO Created log for partition connect-offsets-16 in /tmp/kafka-logs/connect-offsets-16 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,745] INFO [Partition connect-offsets-16 broker=0] No checkpointed highwatermark is found for partition connect-offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:31:33,745] INFO [Partition connect-offsets-16 broker=0] Log loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,753] INFO [LogLoader partition=connect-offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,753] INFO Created log for partition connect-offsets-1 in /tmp/kafka-logs/connect-offsets-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,753] INFO [Partition connect-offsets-1 broker=0] No checkpointed highwatermark is found for partition connect-offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:31:33,753] INFO [Partition connect-offsets-1 broker=0] Log loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,761] INFO [LogLoader partition=connect-offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,761] INFO Created log for partition connect-offsets-12 in /tmp/kafka-logs/connect-offsets-12 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,761] INFO [Partition connect-offsets-12 broker=0] No checkpointed highwatermark is found for partition connect-offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:31:33,761] INFO [Partition connect-offsets-12 broker=0] Log loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,768] INFO [LogLoader partition=connect-offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,768] INFO Created log for partition connect-offsets-11 in /tmp/kafka-logs/connect-offsets-11 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,768] INFO [Partition connect-offsets-11 broker=0] No checkpointed highwatermark is found for partition connect-offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:31:33,768] INFO [Partition connect-offsets-11 broker=0] Log loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,775] INFO [LogLoader partition=connect-offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,775] INFO Created log for partition connect-offsets-22 in /tmp/kafka-logs/connect-offsets-22 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,775] INFO [Partition connect-offsets-22 broker=0] No checkpointed highwatermark is found for partition connect-offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:31:33,775] INFO [Partition connect-offsets-22 broker=0] Log loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,783] INFO [LogLoader partition=connect-offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,783] INFO Created log for partition connect-offsets-7 in /tmp/kafka-logs/connect-offsets-7 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,783] INFO [Partition connect-offsets-7 broker=0] No checkpointed highwatermark is found for partition connect-offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:31:33,784] INFO [Partition connect-offsets-7 broker=0] Log loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,792] INFO [LogLoader partition=connect-offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,792] INFO Created log for partition connect-offsets-0 in /tmp/kafka-logs/connect-offsets-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,792] INFO [Partition connect-offsets-0 broker=0] No checkpointed highwatermark is found for partition connect-offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,792] INFO [Partition connect-offsets-0 broker=0] Log loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,800] INFO [LogLoader partition=connect-offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,800] INFO Created log for partition connect-offsets-19 in /tmp/kafka-logs/connect-offsets-19 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,800] INFO [Partition connect-offsets-19 broker=0] No checkpointed highwatermark is found for partition connect-offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:31:33,800] INFO [Partition connect-offsets-19 broker=0] Log loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,805] INFO [LogLoader partition=connect-offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,805] INFO Created log for partition connect-offsets-15 in /tmp/kafka-logs/connect-offsets-15 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,805] INFO [Partition connect-offsets-15 broker=0] No checkpointed highwatermark is found for partition connect-offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:31:33,805] INFO [Partition connect-offsets-15 broker=0] Log loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,811] INFO [LogLoader partition=connect-offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,811] INFO Created log for partition connect-offsets-10 in /tmp/kafka-logs/connect-offsets-10 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,811] INFO [Partition connect-offsets-10 broker=0] No checkpointed highwatermark is found for partition connect-offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:31:33,811] INFO [Partition connect-offsets-10 broker=0] Log loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,816] INFO [LogLoader partition=connect-offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,817] INFO Created log for partition connect-offsets-21 in /tmp/kafka-logs/connect-offsets-21 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,817] INFO [Partition connect-offsets-21 broker=0] No checkpointed highwatermark is found for partition connect-offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:31:33,817] INFO [Partition connect-offsets-21 broker=0] Log loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,825] INFO [LogLoader partition=connect-offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,825] INFO Created log for partition connect-offsets-6 in /tmp/kafka-logs/connect-offsets-6 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,825] INFO [Partition connect-offsets-6 broker=0] No checkpointed highwatermark is found for partition connect-offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:31:33,825] INFO [Partition connect-offsets-6 broker=0] Log loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,834] INFO [LogLoader partition=connect-offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,834] INFO Created log for partition connect-offsets-18 in /tmp/kafka-logs/connect-offsets-18 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,834] INFO [Partition connect-offsets-18 broker=0] No checkpointed highwatermark is found for partition connect-offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:31:33,834] INFO [Partition connect-offsets-18 broker=0] Log loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,840] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,841] INFO Created log for partition connect-offsets-3 in /tmp/kafka-logs/connect-offsets-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,841] INFO [Partition connect-offsets-3 broker=0] No checkpointed highwatermark is found for partition connect-offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:31:33,841] INFO [Partition connect-offsets-3 broker=0] Log loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,848] INFO [LogLoader partition=connect-offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,849] INFO Created log for partition connect-offsets-14 in /tmp/kafka-logs/connect-offsets-14 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,849] INFO [Partition connect-offsets-14 broker=0] No checkpointed highwatermark is found for partition connect-offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:31:33,849] INFO [Partition connect-offsets-14 broker=0] Log loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,923] INFO Creating topic connect-status with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:31:33,953] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-status-4, connect-status-3, connect-status-2, connect-status-0, connect-status-1) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:31:33,955] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,955] INFO Created log for partition connect-status-4 in /tmp/kafka-logs/connect-status-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,956] INFO [Partition connect-status-4 broker=0] No checkpointed highwatermark is found for partition connect-status-4 (kafka.cluster.Partition)
[2025-01-06 17:31:33,956] INFO [Partition connect-status-4 broker=0] Log loaded for partition connect-status-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,964] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,964] INFO Created log for partition connect-status-1 in /tmp/kafka-logs/connect-status-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,964] INFO [Partition connect-status-1 broker=0] No checkpointed highwatermark is found for partition connect-status-1 (kafka.cluster.Partition)
[2025-01-06 17:31:33,964] INFO [Partition connect-status-1 broker=0] Log loaded for partition connect-status-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,969] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,970] INFO Created log for partition connect-status-0 in /tmp/kafka-logs/connect-status-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,970] INFO [Partition connect-status-0 broker=0] No checkpointed highwatermark is found for partition connect-status-0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,970] INFO [Partition connect-status-0 broker=0] Log loaded for partition connect-status-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,978] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,978] INFO Created log for partition connect-status-3 in /tmp/kafka-logs/connect-status-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,978] INFO [Partition connect-status-3 broker=0] No checkpointed highwatermark is found for partition connect-status-3 (kafka.cluster.Partition)
[2025-01-06 17:31:33,978] INFO [Partition connect-status-3 broker=0] Log loaded for partition connect-status-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:33,984] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:33,984] INFO Created log for partition connect-status-2 in /tmp/kafka-logs/connect-status-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:33,985] INFO [Partition connect-status-2 broker=0] No checkpointed highwatermark is found for partition connect-status-2 (kafka.cluster.Partition)
[2025-01-06 17:31:33,985] INFO [Partition connect-status-2 broker=0] Log loaded for partition connect-status-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,015] INFO Creating topic connect-configs with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:31:34,034] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(connect-configs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:31:34,036] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,036] INFO Created log for partition connect-configs-0 in /tmp/kafka-logs/connect-configs-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:31:34,036] INFO [Partition connect-configs-0 broker=0] No checkpointed highwatermark is found for partition connect-configs-0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,036] INFO [Partition connect-configs-0 broker=0] Log loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,060] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:31:34,145] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:31:34,147] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,148] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,148] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:31:34,148] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,156] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,156] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,156] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:31:34,156] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,163] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,164] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,164] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-01-06 17:31:34,164] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,170] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,170] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,170] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:31:34,170] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,179] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,179] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,180] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-01-06 17:31:34,180] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,186] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,186] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,186] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-01-06 17:31:34,186] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,195] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,195] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,195] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:31:34,195] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,201] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,202] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,202] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-01-06 17:31:34,202] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,210] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,210] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,210] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:31:34,210] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,219] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,219] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,219] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:31:34,220] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,227] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,228] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,228] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-01-06 17:31:34,228] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,236] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,236] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,237] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-01-06 17:31:34,237] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,245] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,245] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,245] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-01-06 17:31:34,245] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,253] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,254] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,254] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:31:34,254] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,264] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,265] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,265] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:31:34,265] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,274] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,274] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,274] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-01-06 17:31:34,274] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,284] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,284] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,284] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-01-06 17:31:34,284] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,311] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,316] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,316] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:31:34,316] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,390] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,392] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,392] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:31:34,398] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,414] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,415] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,415] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:31:34,415] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,432] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,432] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,432] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-01-06 17:31:34,432] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,448] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,449] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,449] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-01-06 17:31:34,449] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,465] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,466] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,466] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-01-06 17:31:34,466] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,478] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,479] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,479] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:31:34,479] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,490] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,491] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,491] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-01-06 17:31:34,491] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,504] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,505] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,505] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-01-06 17:31:34,505] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,514] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,515] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,516] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:31:34,516] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,524] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,526] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,526] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:31:34,526] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,537] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,538] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,538] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-01-06 17:31:34,538] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,548] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,549] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,549] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-01-06 17:31:34,549] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,574] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,575] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,575] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:31:34,575] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,583] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,583] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,583] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:31:34,583] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,592] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,593] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,593] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-01-06 17:31:34,593] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,605] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,606] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,606] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:31:34,606] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,616] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,616] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,617] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-01-06 17:31:34,617] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,623] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,624] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,624] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:31:34,624] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,633] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,634] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,634] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-01-06 17:31:34,634] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,641] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,641] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,641] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,642] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,649] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,649] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,650] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-01-06 17:31:34,650] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,658] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,659] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,659] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:31:34,659] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,666] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,667] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,667] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:31:34,667] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,675] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,676] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,676] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-01-06 17:31:34,676] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,684] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,684] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,684] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-01-06 17:31:34,684] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,695] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,696] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,696] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:31:34,696] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,705] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,706] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,706] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:31:34,706] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,714] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,714] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,714] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-01-06 17:31:34,714] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,722] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,722] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,722] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:31:34,722] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,733] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,734] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,734] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-01-06 17:31:34,734] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,742] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,742] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,742] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:31:34,742] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,749] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:31:34,749] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:31:34,750] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-01-06 17:31:34,750] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:31:34,755] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,756] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,757] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,757] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 3 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,759] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 3 milliseconds for epoch 0, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:31:34,811] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-cluster in Empty state. Created a new member id connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,815] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 with group instance id None; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,816] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 1 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:31:34,825] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,508] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,508] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 2 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,511] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,526] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 2 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,526] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 3 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,528] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:11,695] INFO Creating topic db.history.internal with configuration {cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:11,721] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(db.history.internal-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:11,723] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:11,724] INFO Created log for partition db.history.internal-0 in /tmp/kafka-logs/db.history.internal-0 with properties {cleanup.policy=delete, retention.bytes=-1, retention.ms=9223372036854775807} (kafka.log.LogManager)
[2025-01-06 17:32:11,724] INFO [Partition db.history.internal-0 broker=0] No checkpointed highwatermark is found for partition db.history.internal-0 (kafka.cluster.Partition)
[2025-01-06 17:32:11,724] INFO [Partition db.history.internal-0 broker=0] Log loaded for partition db.history.internal-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:12,799] INFO Creating topic kafka.leafy_factory.factories with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:12,831] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.factories-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:12,836] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:12,837] INFO Created log for partition kafka.leafy_factory.factories-0 in /tmp/kafka-logs/kafka.leafy_factory.factories-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:12,837] INFO [Partition kafka.leafy_factory.factories-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.factories-0 (kafka.cluster.Partition)
[2025-01-06 17:32:12,837] INFO [Partition kafka.leafy_factory.factories-0 broker=0] Log loaded for partition kafka.leafy_factory.factories-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:12,944] INFO Creating topic kafka.leafy_factory.jobs with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:12,970] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:12,972] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:12,973] INFO Created log for partition kafka.leafy_factory.jobs-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:12,974] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs-0 (kafka.cluster.Partition)
[2025-01-06 17:32:12,974] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,062] INFO Creating topic kafka.leafy_factory.jobs_machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,089] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs_machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,092] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,093] INFO Created log for partition kafka.leafy_factory.jobs_machines-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs_machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,093] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs_machines-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,094] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs_machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,179] INFO Creating topic kafka.leafy_factory.machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,203] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,206] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,207] INFO Created log for partition kafka.leafy_factory.machines-0 in /tmp/kafka-logs/kafka.leafy_factory.machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,207] INFO [Partition kafka.leafy_factory.machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.machines-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,207] INFO [Partition kafka.leafy_factory.machines-0 broker=0] Log loaded for partition kafka.leafy_factory.machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,316] INFO Creating topic kafka.leafy_factory.product_cost with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,345] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.product_cost-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,349] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,350] INFO Created log for partition kafka.leafy_factory.product_cost-0 in /tmp/kafka-logs/kafka.leafy_factory.product_cost-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,350] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.product_cost-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,350] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] Log loaded for partition kafka.leafy_factory.product_cost-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,451] INFO Creating topic kafka.leafy_factory.production_lines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,477] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.production_lines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,480] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,480] INFO Created log for partition kafka.leafy_factory.production_lines-0 in /tmp/kafka-logs/kafka.leafy_factory.production_lines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,480] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.production_lines-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,480] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] Log loaded for partition kafka.leafy_factory.production_lines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,569] INFO Creating topic kafka.leafy_factory.products with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,594] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,597] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,598] INFO Created log for partition kafka.leafy_factory.products-0 in /tmp/kafka-logs/kafka.leafy_factory.products-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,598] INFO [Partition kafka.leafy_factory.products-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,598] INFO [Partition kafka.leafy_factory.products-0 broker=0] Log loaded for partition kafka.leafy_factory.products-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,710] INFO Creating topic kafka.leafy_factory.products_raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,733] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products_raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,736] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,737] INFO Created log for partition kafka.leafy_factory.products_raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,737] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products_raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,737] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.products_raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,850] INFO Creating topic kafka.leafy_factory.raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:13,879] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:13,883] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:13,883] INFO Created log for partition kafka.leafy_factory.raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:13,883] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,884] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:13,979] INFO Creating topic kafka.leafy_factory.work_orders with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:32:14,008] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.work_orders-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:32:14,011] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:32:14,011] INFO Created log for partition kafka.leafy_factory.work_orders-0 in /tmp/kafka-logs/kafka.leafy_factory.work_orders-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:32:14,011] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.work_orders-0 (kafka.cluster.Partition)
[2025-01-06 17:32:14,011] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] Log loaded for partition kafka.leafy_factory.work_orders-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:32:28,114] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 3 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,115] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 4 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,116] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,136] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 4 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,136] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 5 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,137] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,219] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-mongodb-sink-connector in Empty state. Created a new member id connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,222] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink-connector in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb with group instance id None; client reason: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,227] INFO [GroupCoordinator 0]: Stabilized group connect-mongodb-sink-connector generation 1 (__consumer_offsets-33) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:32:28,236] INFO [GroupCoordinator 0]: Assignment received from leader connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb for group connect-mongodb-sink-connector for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,234] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 5 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,235] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 6 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,239] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 6. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,397] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink-connector in state PreparingRebalance with old generation 1 (__consumer_offsets-33) (reason: Removing member connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb on LeaveGroup; client reason: the consumer is being closed) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,397] INFO [GroupCoordinator 0]: Group connect-mongodb-sink-connector with generation 2 is now empty (__consumer_offsets-33) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,399] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=connector-consumer-mongodb-sink-connector-0-224a7233-0fb7-437c-b7bf-1b89ee4ba5cb, groupInstanceId=None, clientId=connector-consumer-mongodb-sink-connector-0, clientHost=/192.168.1.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group connect-mongodb-sink-connector through explicit `LeaveGroup`; client reason: the consumer is being closed (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,413] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 6 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,413] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 7 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:08,414] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 7. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,497] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 7 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,498] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 8 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,500] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 8. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,517] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 8 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,518] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 9 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,519] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-3e060fd8-484c-4206-81ca-7d45de862356 for group connect-cluster for generation 9. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,561] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-mongodb-sink-connector in Empty state. Created a new member id connector-consumer-mongodb-sink-connector-0-4bac398d-4e7e-4e88-8cd2-21e50e200191 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,563] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink-connector in state PreparingRebalance with old generation 2 (__consumer_offsets-33) (reason: Adding new member connector-consumer-mongodb-sink-connector-0-4bac398d-4e7e-4e88-8cd2-21e50e200191 with group instance id None; client reason: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-4bac398d-4e7e-4e88-8cd2-21e50e200191) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,563] INFO [GroupCoordinator 0]: Stabilized group connect-mongodb-sink-connector generation 3 (__consumer_offsets-33) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:38:32,565] INFO [GroupCoordinator 0]: Assignment received from leader connector-consumer-mongodb-sink-connector-0-4bac398d-4e7e-4e88-8cd2-21e50e200191 for group connect-mongodb-sink-connector for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:39:24,984] WARN Session 0x10006c533700000 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x10006c533700000, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:39:26,539] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:26,543] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-01-06 17:39:26,546] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-01-06 17:39:26,567] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2025-01-06 17:39:26,571] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:39:26,571] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:39:26,571] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:39:26,572] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:39:26,577] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-01-06 17:39:26,578] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:39:26,580] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-01-06 17:39:26,582] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,583] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,583] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,584] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-01-06 17:39:26,585] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,585] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,586] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,586] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:39:26,587] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-01-06 17:39:26,587] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:39:26,587] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:39:26,587] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:39:26,588] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:39:26,588] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:39:26,589] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,589] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,589] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,589] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,589] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,590] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,590] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:39:26,591] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-01-06 17:39:26,591] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:39:26,592] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:39:26,592] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:39:26,592] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:39:26,592] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:39:26,592] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:39:26,592] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-01-06 17:39:26,592] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,593] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,593] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,593] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,593] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,594] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,595] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,595] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,595] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:39:26,601] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:39:26,601] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:39:26,601] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:39:26,602] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-01-06 17:39:26,602] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,602] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,602] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,604] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:39:26,604] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,604] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,604] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:39:26,605] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2025-01-06 17:39:26,605] INFO Shutting down. (kafka.log.LogManager)
[2025-01-06 17:39:26,606] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:39:26,606] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:39:26,606] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:39:26,636] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs_machines-0] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,651] INFO [ProducerStateManager partition=connect-status-4] Wrote producer snapshot at offset 10 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,671] INFO [ProducerStateManager partition=connect-offsets-3] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,718] INFO [ProducerStateManager partition=connect-status-0] Wrote producer snapshot at offset 14 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,733] INFO [ProducerStateManager partition=db.history.internal-0] Wrote producer snapshot at offset 24 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,744] INFO [ProducerStateManager partition=kafka.leafy_factory.jobs-0] Wrote producer snapshot at offset 2 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,748] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:26,757] INFO [ProducerStateManager partition=connect-configs-0] Wrote producer snapshot at offset 12 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,784] INFO [ProducerStateManager partition=connect-status-2] Wrote producer snapshot at offset 19 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,812] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 9 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,829] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 13 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,837] INFO [ProducerStateManager partition=kafka.leafy_factory.factories-0] Wrote producer snapshot at offset 1 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,857] INFO [ProducerStateManager partition=connect-status-1] Wrote producer snapshot at offset 38 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,886] INFO [ProducerStateManager partition=connect-status-3] Wrote producer snapshot at offset 8 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,907] INFO [ProducerStateManager partition=kafka.leafy_factory.machines-0] Wrote producer snapshot at offset 4 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:39:26,921] INFO [ProducerStateManager partition=kafka.leafy_factory.production_lines-0] Wrote producer snapshot at offset 2 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,921] WARN Session 0x10006c533700000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1062)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2025-01-06 17:39:26,939] INFO [ProducerStateManager partition=kafka.leafy_factory.work_orders-0] Wrote producer snapshot at offset 7 with 0 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,946] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:26,954] INFO [ProducerStateManager partition=kafka.leafy_factory.product_cost-0] Wrote producer snapshot at offset 7 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,966] INFO [ProducerStateManager partition=kafka.leafy_factory.raw_materials-0] Wrote producer snapshot at offset 8 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,981] INFO [ProducerStateManager partition=kafka.leafy_factory.products-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:26,999] INFO [ProducerStateManager partition=kafka.leafy_factory.products_raw_materials-0] Wrote producer snapshot at offset 8 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2025-01-06 17:39:27,037] INFO Shutdown complete. (kafka.log.LogManager)
[2025-01-06 17:39:27,040] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:39:27,040] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:39:27,040] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:39:27,041] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:39:27,147] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:27,338] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:27,554] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:28,063] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:28,283] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:39:28,283] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:39:28,391] INFO Session: 0x10006c533700000 closed (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:39:28,391] INFO EventThread shut down for session: 0x10006c533700000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:39:28,392] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:39:28,392] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,394] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,394] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,395] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,396] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,396] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,396] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:39:28,397] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-01-06 17:39:28,409] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2025-01-06 17:39:28,411] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:39:28,411] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:39:28,411] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-01-06 17:39:28,412] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2025-01-06 17:39:28,412] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:39:28,413] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2025-01-06 17:40:42,237] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,238] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,239] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,239] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,239] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,239] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,240] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:40:42,240] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:40:42,240] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-01-06 17:40:42,240] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-01-06 17:40:42,240] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-01-06 17:40:42,240] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,240] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,241] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,241] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,241] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,241] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-01-06 17:40:42,241] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-01-06 17:40:42,245] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@9225652 (org.apache.zookeeper.server.ServerMetrics)
[2025-01-06 17:40:42,246] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:40:42,246] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2025-01-06 17:40:42,247] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:40:42,250] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,250] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,264] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,265] INFO Server environment:host.name=192.168.1.5 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,265] INFO Server environment:java.version=23 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,265] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,265] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,265] INFO Server environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.arch=aarch64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.version=15.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:user.name=gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.memory.free=488MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,266] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,267] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,267] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,267] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,267] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,267] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2025-01-06 17:40:42,268] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,268] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,268] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:40:42,268] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,269] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2025-01-06 17:40:42,270] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,271] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,271] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:40:42,271] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2025-01-06 17:40:42,271] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,273] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:40:42,274] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-01-06 17:40:42,274] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 22 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:40:42,279] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-01-06 17:40:42,288] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:40:42,288] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2025-01-06 17:40:42,288] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:40:42,288] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:40:42,290] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2025-01-06 17:40:42,290] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:40:42,291] INFO Snapshot loaded in 3 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2025-01-06 17:40:42,292] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-01-06 17:40:42,292] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2025-01-06 17:40:42,295] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2025-01-06 17:40:42,295] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2025-01-06 17:40:42,301] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2025-01-06 17:40:42,301] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2025-01-06 17:40:57,971] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-01-06 17:40:58,050] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-01-06 17:40:58,082] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2025-01-06 17:40:58,082] INFO starting (kafka.server.KafkaServer)
[2025-01-06 17:40:58,083] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-01-06 17:40:58,092] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:40:58,112] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,113] INFO Client environment:host.name=192.168.1.5 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,113] INFO Client environment:java.version=23 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,113] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,113] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-23.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,113] INFO Client environment:java.class.path=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/activation-1.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/argparse4j-0.7.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/audience-annotations-0.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/caffeine-2.9.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-beanutils-1.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-cli-1.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-collections-3.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-digester-2.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-io-2.14.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-lang3-3.12.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-logging-1.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/commons-validator-1.7.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-json-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-mirror-client-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-runtime-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/connect-transforms-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/error_prone_annotations-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-api-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-locator-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/hk2-utils-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-core-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-databind-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-afterburner-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.inject-2.6.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javassist-3.29.2-GA.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.activation-api-1.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.annotation-api-1.3.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jaxb-api-2.3.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-client-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-common-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-hk2-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jersey-server-2.39.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-client-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-http-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-io-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-security-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-server-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jline-3.25.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jose4j-0.9.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/jsr305-3.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-clients-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-metadata-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-raft-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-server-common-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-shell-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-storage-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-examples-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-scala_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-tools-api-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/kafka_2.13-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/lz4-java-1.8.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/maven-artifact-3.9.6.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-2.2.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/metrics-core-4.1.12.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-buffer-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-codec-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-handler-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-resolver-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/paranamer-2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/pcollections-4.0.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/plexus-utils-3.5.1.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/protobuf-java-3.25.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reflections-0.10.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/reload4j-1.2.25.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/rocksdbjni-7.9.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-library-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-logging_2.13-3.9.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/scala-reflect-2.13.14.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-api-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/snappy-java-1.1.10.5.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/swagger-annotations-2.2.8.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/trogdor-3.9.0.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zookeeper-jute-3.8.4.jar:/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:java.library.path=/Users/gio.rodriguez/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:java.io.tmpdir=/var/folders/v3/lhczvh3n5wlf525vh6jqq3vh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.arch=aarch64 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.version=15.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:user.name=gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:user.home=/Users/gio.rodriguez (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:user.dir=/Users/gio.rodriguez/Documents/github_repositories/leafy_factory/backend/kafka_2.13-3.9.0 (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,114] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,115] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@5e403b4a (org.apache.zookeeper.ZooKeeper)
[2025-01-06 17:40:58,117] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-01-06 17:40:58,120] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:40:58,121] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:40:58,121] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:40:58,123] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:51103, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:40:58,127] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-01-06 17:40:58,137] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10006cde5b80000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-01-06 17:40:58,138] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-01-06 17:40:58,293] INFO Cluster ID = iJw9MDkxQIKDop3aj4gHuw (kafka.server.KafkaServer)
[2025-01-06 17:40:58,311] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2025-01-06 17:40:58,321] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:40:58,322] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:40:58,322] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:40:58,323] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-01-06 17:40:58,325] INFO [KafkaServer id=0] Rewriting /tmp/kafka-logs/meta.properties (kafka.server.KafkaServer)
[2025-01-06 17:40:58,344] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
[2025-01-06 17:40:58,346] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
[2025-01-06 17:40:58,349] INFO Loaded 0 logs in 5ms (kafka.log.LogManager)
[2025-01-06 17:40:58,349] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-01-06 17:40:58,350] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-01-06 17:40:58,386] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2025-01-06 17:40:58,396] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2025-01-06 17:40:58,400] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:40:58,408] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:40:58,522] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2025-01-06 17:40:58,528] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2025-01-06 17:40:58,530] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:40:58,538] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,539] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,539] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,539] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,539] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,544] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-01-06 17:40:58,544] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2025-01-06 17:40:58,551] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-01-06 17:40:58,561] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1736206858556,1736206858556,1,0,0,72065075430031360,206,0,25
 (kafka.zk.KafkaZkClient)
[2025-01-06 17:40:58,561] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://192.168.1.5:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2025-01-06 17:40:58,576] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,578] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,578] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,580] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2025-01-06 17:40:58,584] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:40:58,585] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:40:58,588] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2025-01-06 17:40:58,590] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:40:58,591] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-01-06 17:40:58,592] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-01-06 17:40:58,602] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2025-01-06 17:40:58,612] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-01-06 17:40:58,620] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:40:58,621] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (/192.168.1.5:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:40:58,621] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-01-06 17:40:58,622] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2025-01-06 17:40:58,626] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2025-01-06 17:40:58,628] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2025-01-06 17:40:58,629] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:40:58,629] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2025-01-06 17:40:58,629] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:40:58,629] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2025-01-06 17:40:58,631] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:40:58,631] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:40:58,631] INFO Kafka startTimeMs: 1736206858629 (org.apache.kafka.common.utils.AppInfoParser)
[2025-01-06 17:40:58,631] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-01-06 17:40:58,815] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:40:58,833] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 192.168.1.5:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2025-01-06 17:41:07,528] INFO Creating topic connect-offsets with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:07,618] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-offsets-20, connect-offsets-6, connect-offsets-17, connect-offsets-15, connect-offsets-7, connect-offsets-24, connect-offsets-16, connect-offsets-3, connect-offsets-21, connect-offsets-11, connect-offsets-10, connect-offsets-2, connect-offsets-18, connect-offsets-23, connect-offsets-4, connect-offsets-12, connect-offsets-5, connect-offsets-13, connect-offsets-14, connect-offsets-0, connect-offsets-8, connect-offsets-9, connect-offsets-1, connect-offsets-19, connect-offsets-22) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:07,640] INFO [LogLoader partition=connect-offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,644] INFO Created log for partition connect-offsets-24 in /tmp/kafka-logs/connect-offsets-24 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,645] INFO [Partition connect-offsets-24 broker=0] No checkpointed highwatermark is found for partition connect-offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:41:07,645] INFO [Partition connect-offsets-24 broker=0] Log loaded for partition connect-offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,658] INFO [LogLoader partition=connect-offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,658] INFO Created log for partition connect-offsets-9 in /tmp/kafka-logs/connect-offsets-9 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,663] INFO [Partition connect-offsets-9 broker=0] No checkpointed highwatermark is found for partition connect-offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:41:07,663] INFO [Partition connect-offsets-9 broker=0] Log loaded for partition connect-offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,674] INFO [LogLoader partition=connect-offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,675] INFO Created log for partition connect-offsets-20 in /tmp/kafka-logs/connect-offsets-20 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,676] INFO [Partition connect-offsets-20 broker=0] No checkpointed highwatermark is found for partition connect-offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:41:07,676] INFO [Partition connect-offsets-20 broker=0] Log loaded for partition connect-offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,685] INFO [LogLoader partition=connect-offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,686] INFO Created log for partition connect-offsets-5 in /tmp/kafka-logs/connect-offsets-5 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,686] INFO [Partition connect-offsets-5 broker=0] No checkpointed highwatermark is found for partition connect-offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:41:07,686] INFO [Partition connect-offsets-5 broker=0] Log loaded for partition connect-offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,693] INFO [LogLoader partition=connect-offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,693] INFO Created log for partition connect-offsets-17 in /tmp/kafka-logs/connect-offsets-17 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,693] INFO [Partition connect-offsets-17 broker=0] No checkpointed highwatermark is found for partition connect-offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:41:07,693] INFO [Partition connect-offsets-17 broker=0] Log loaded for partition connect-offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,697] INFO [LogLoader partition=connect-offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,698] INFO Created log for partition connect-offsets-2 in /tmp/kafka-logs/connect-offsets-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,698] INFO [Partition connect-offsets-2 broker=0] No checkpointed highwatermark is found for partition connect-offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:41:07,698] INFO [Partition connect-offsets-2 broker=0] Log loaded for partition connect-offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,707] INFO [LogLoader partition=connect-offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,707] INFO Created log for partition connect-offsets-13 in /tmp/kafka-logs/connect-offsets-13 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,707] INFO [Partition connect-offsets-13 broker=0] No checkpointed highwatermark is found for partition connect-offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:41:07,707] INFO [Partition connect-offsets-13 broker=0] Log loaded for partition connect-offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,715] INFO [LogLoader partition=connect-offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,716] INFO Created log for partition connect-offsets-8 in /tmp/kafka-logs/connect-offsets-8 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,716] INFO [Partition connect-offsets-8 broker=0] No checkpointed highwatermark is found for partition connect-offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:41:07,716] INFO [Partition connect-offsets-8 broker=0] Log loaded for partition connect-offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,725] INFO [LogLoader partition=connect-offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,725] INFO Created log for partition connect-offsets-4 in /tmp/kafka-logs/connect-offsets-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,725] INFO [Partition connect-offsets-4 broker=0] No checkpointed highwatermark is found for partition connect-offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:41:07,725] INFO [Partition connect-offsets-4 broker=0] Log loaded for partition connect-offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,730] INFO [LogLoader partition=connect-offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,731] INFO Created log for partition connect-offsets-23 in /tmp/kafka-logs/connect-offsets-23 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,731] INFO [Partition connect-offsets-23 broker=0] No checkpointed highwatermark is found for partition connect-offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:41:07,731] INFO [Partition connect-offsets-23 broker=0] Log loaded for partition connect-offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,738] INFO [LogLoader partition=connect-offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,739] INFO Created log for partition connect-offsets-16 in /tmp/kafka-logs/connect-offsets-16 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,739] INFO [Partition connect-offsets-16 broker=0] No checkpointed highwatermark is found for partition connect-offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:41:07,739] INFO [Partition connect-offsets-16 broker=0] Log loaded for partition connect-offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,747] INFO [LogLoader partition=connect-offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,747] INFO Created log for partition connect-offsets-1 in /tmp/kafka-logs/connect-offsets-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,747] INFO [Partition connect-offsets-1 broker=0] No checkpointed highwatermark is found for partition connect-offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:41:07,747] INFO [Partition connect-offsets-1 broker=0] Log loaded for partition connect-offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,757] INFO [LogLoader partition=connect-offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,758] INFO Created log for partition connect-offsets-12 in /tmp/kafka-logs/connect-offsets-12 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,758] INFO [Partition connect-offsets-12 broker=0] No checkpointed highwatermark is found for partition connect-offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:41:07,758] INFO [Partition connect-offsets-12 broker=0] Log loaded for partition connect-offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,767] INFO [LogLoader partition=connect-offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,767] INFO Created log for partition connect-offsets-11 in /tmp/kafka-logs/connect-offsets-11 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,767] INFO [Partition connect-offsets-11 broker=0] No checkpointed highwatermark is found for partition connect-offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:41:07,767] INFO [Partition connect-offsets-11 broker=0] Log loaded for partition connect-offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,774] INFO [LogLoader partition=connect-offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,774] INFO Created log for partition connect-offsets-22 in /tmp/kafka-logs/connect-offsets-22 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,774] INFO [Partition connect-offsets-22 broker=0] No checkpointed highwatermark is found for partition connect-offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:41:07,774] INFO [Partition connect-offsets-22 broker=0] Log loaded for partition connect-offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,783] INFO [LogLoader partition=connect-offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,783] INFO Created log for partition connect-offsets-7 in /tmp/kafka-logs/connect-offsets-7 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,783] INFO [Partition connect-offsets-7 broker=0] No checkpointed highwatermark is found for partition connect-offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:41:07,783] INFO [Partition connect-offsets-7 broker=0] Log loaded for partition connect-offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,794] INFO [LogLoader partition=connect-offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,794] INFO Created log for partition connect-offsets-0 in /tmp/kafka-logs/connect-offsets-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,794] INFO [Partition connect-offsets-0 broker=0] No checkpointed highwatermark is found for partition connect-offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,794] INFO [Partition connect-offsets-0 broker=0] Log loaded for partition connect-offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,802] INFO [LogLoader partition=connect-offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,802] INFO Created log for partition connect-offsets-19 in /tmp/kafka-logs/connect-offsets-19 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,802] INFO [Partition connect-offsets-19 broker=0] No checkpointed highwatermark is found for partition connect-offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:41:07,802] INFO [Partition connect-offsets-19 broker=0] Log loaded for partition connect-offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,810] INFO [LogLoader partition=connect-offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,810] INFO Created log for partition connect-offsets-15 in /tmp/kafka-logs/connect-offsets-15 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,810] INFO [Partition connect-offsets-15 broker=0] No checkpointed highwatermark is found for partition connect-offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:41:07,810] INFO [Partition connect-offsets-15 broker=0] Log loaded for partition connect-offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,816] INFO [LogLoader partition=connect-offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,816] INFO Created log for partition connect-offsets-10 in /tmp/kafka-logs/connect-offsets-10 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,816] INFO [Partition connect-offsets-10 broker=0] No checkpointed highwatermark is found for partition connect-offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:41:07,816] INFO [Partition connect-offsets-10 broker=0] Log loaded for partition connect-offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,826] INFO [LogLoader partition=connect-offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,827] INFO Created log for partition connect-offsets-21 in /tmp/kafka-logs/connect-offsets-21 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,827] INFO [Partition connect-offsets-21 broker=0] No checkpointed highwatermark is found for partition connect-offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:41:07,827] INFO [Partition connect-offsets-21 broker=0] Log loaded for partition connect-offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,833] INFO [LogLoader partition=connect-offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,833] INFO Created log for partition connect-offsets-6 in /tmp/kafka-logs/connect-offsets-6 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,833] INFO [Partition connect-offsets-6 broker=0] No checkpointed highwatermark is found for partition connect-offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:41:07,833] INFO [Partition connect-offsets-6 broker=0] Log loaded for partition connect-offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,841] INFO [LogLoader partition=connect-offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,841] INFO Created log for partition connect-offsets-18 in /tmp/kafka-logs/connect-offsets-18 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,842] INFO [Partition connect-offsets-18 broker=0] No checkpointed highwatermark is found for partition connect-offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:41:07,842] INFO [Partition connect-offsets-18 broker=0] Log loaded for partition connect-offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,852] INFO [LogLoader partition=connect-offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,852] INFO Created log for partition connect-offsets-3 in /tmp/kafka-logs/connect-offsets-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,852] INFO [Partition connect-offsets-3 broker=0] No checkpointed highwatermark is found for partition connect-offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:41:07,852] INFO [Partition connect-offsets-3 broker=0] Log loaded for partition connect-offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,858] INFO [LogLoader partition=connect-offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,858] INFO Created log for partition connect-offsets-14 in /tmp/kafka-logs/connect-offsets-14 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,858] INFO [Partition connect-offsets-14 broker=0] No checkpointed highwatermark is found for partition connect-offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:41:07,858] INFO [Partition connect-offsets-14 broker=0] Log loaded for partition connect-offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,939] INFO Creating topic connect-status with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:07,970] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(connect-status-4, connect-status-3, connect-status-2, connect-status-0, connect-status-1) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:07,973] INFO [LogLoader partition=connect-status-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,973] INFO Created log for partition connect-status-4 in /tmp/kafka-logs/connect-status-4 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,974] INFO [Partition connect-status-4 broker=0] No checkpointed highwatermark is found for partition connect-status-4 (kafka.cluster.Partition)
[2025-01-06 17:41:07,975] INFO [Partition connect-status-4 broker=0] Log loaded for partition connect-status-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,980] INFO [LogLoader partition=connect-status-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,980] INFO Created log for partition connect-status-1 in /tmp/kafka-logs/connect-status-1 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,980] INFO [Partition connect-status-1 broker=0] No checkpointed highwatermark is found for partition connect-status-1 (kafka.cluster.Partition)
[2025-01-06 17:41:07,980] INFO [Partition connect-status-1 broker=0] Log loaded for partition connect-status-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,988] INFO [LogLoader partition=connect-status-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,988] INFO Created log for partition connect-status-0 in /tmp/kafka-logs/connect-status-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,988] INFO [Partition connect-status-0 broker=0] No checkpointed highwatermark is found for partition connect-status-0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,988] INFO [Partition connect-status-0 broker=0] Log loaded for partition connect-status-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:07,996] INFO [LogLoader partition=connect-status-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:07,996] INFO Created log for partition connect-status-3 in /tmp/kafka-logs/connect-status-3 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:07,996] INFO [Partition connect-status-3 broker=0] No checkpointed highwatermark is found for partition connect-status-3 (kafka.cluster.Partition)
[2025-01-06 17:41:07,996] INFO [Partition connect-status-3 broker=0] Log loaded for partition connect-status-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,004] INFO [LogLoader partition=connect-status-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,005] INFO Created log for partition connect-status-2 in /tmp/kafka-logs/connect-status-2 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:08,005] INFO [Partition connect-status-2 broker=0] No checkpointed highwatermark is found for partition connect-status-2 (kafka.cluster.Partition)
[2025-01-06 17:41:08,005] INFO [Partition connect-status-2 broker=0] Log loaded for partition connect-status-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,031] INFO Creating topic connect-configs with configuration {cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:08,049] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(connect-configs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:08,051] INFO [LogLoader partition=connect-configs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,051] INFO Created log for partition connect-configs-0 in /tmp/kafka-logs/connect-configs-0 with properties {cleanup.policy=compact} (kafka.log.LogManager)
[2025-01-06 17:41:08,052] INFO [Partition connect-configs-0 broker=0] No checkpointed highwatermark is found for partition connect-configs-0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,052] INFO [Partition connect-configs-0 broker=0] Log loaded for partition connect-configs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,077] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 23 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 49 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:08,158] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-37, __consumer_offsets-38, __consumer_offsets-13, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:08,161] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,161] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,161] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-01-06 17:41:08,161] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,169] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,169] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,169] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-01-06 17:41:08,169] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,177] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,177] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,177] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-01-06 17:41:08,177] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,185] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,185] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,185] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-01-06 17:41:08,185] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,192] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,192] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,192] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-01-06 17:41:08,192] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,200] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,200] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,200] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-01-06 17:41:08,200] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,208] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,209] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,209] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-01-06 17:41:08,209] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,216] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,216] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,216] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-01-06 17:41:08,216] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,224] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,225] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,225] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-01-06 17:41:08,225] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,230] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,230] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,230] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-01-06 17:41:08,230] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,239] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,240] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,240] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-01-06 17:41:08,240] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,248] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,249] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,249] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-01-06 17:41:08,249] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,256] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,256] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,256] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-01-06 17:41:08,257] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,264] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,264] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,264] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-01-06 17:41:08,264] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,267] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,268] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,268] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-01-06 17:41:08,268] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,275] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,275] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,275] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-01-06 17:41:08,275] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,281] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,281] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,281] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-01-06 17:41:08,281] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,287] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,287] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,287] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-01-06 17:41:08,287] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,292] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,292] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,292] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-01-06 17:41:08,292] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,298] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,298] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,298] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-01-06 17:41:08,298] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,304] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,305] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,305] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-01-06 17:41:08,305] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,311] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,311] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,311] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-01-06 17:41:08,311] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,319] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,319] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,319] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-01-06 17:41:08,319] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,325] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,325] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,325] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-01-06 17:41:08,325] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,333] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,333] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,334] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-01-06 17:41:08,334] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,341] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,341] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,341] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-01-06 17:41:08,341] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,349] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,349] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,349] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-01-06 17:41:08,349] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,354] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,355] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,357] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-01-06 17:41:08,357] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,361] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,361] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,361] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-01-06 17:41:08,361] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,369] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,369] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,369] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-01-06 17:41:08,369] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,377] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,377] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,377] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-01-06 17:41:08,377] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,382] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,383] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,383] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-01-06 17:41:08,383] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,391] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,392] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,392] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-01-06 17:41:08,392] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,400] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,400] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,400] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-01-06 17:41:08,400] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,406] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,407] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,407] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-01-06 17:41:08,407] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,414] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,414] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,414] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-01-06 17:41:08,414] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,422] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,422] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,422] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-01-06 17:41:08,422] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,429] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,429] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,430] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,430] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,437] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,437] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,437] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-01-06 17:41:08,437] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,443] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,444] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,444] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-01-06 17:41:08,444] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,449] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,449] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,449] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-01-06 17:41:08,449] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,456] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,457] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,457] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-01-06 17:41:08,457] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,465] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,465] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,465] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-01-06 17:41:08,465] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,470] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,471] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,471] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-01-06 17:41:08,471] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,475] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,476] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,476] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-01-06 17:41:08,476] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,479] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,479] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,480] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-01-06 17:41:08,480] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,487] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,487] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,487] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-01-06 17:41:08,487] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,495] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,495] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,495] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-01-06 17:41:08,495] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,503] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,503] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,503] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-01-06 17:41:08,503] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,509] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:08,509] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
[2025-01-06 17:41:08,509] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-01-06 17:41:08,509] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,513] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,514] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds for epoch 0, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,515] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,516] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 2 milliseconds for epoch 0, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2025-01-06 17:41:08,877] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-cluster in Empty state. Created a new member id connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,887] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 with group instance id None; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,889] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 1 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:08,906] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 for group connect-cluster for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,626] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,627] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 2 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,631] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 for group connect-cluster for generation 2. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,651] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 2 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,651] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 3 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,653] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 for group connect-cluster for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:29,831] INFO Creating topic db.history.internal with configuration {cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:29,853] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(db.history.internal-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:29,855] INFO [LogLoader partition=db.history.internal-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:29,856] INFO Created log for partition db.history.internal-0 in /tmp/kafka-logs/db.history.internal-0 with properties {cleanup.policy=delete, retention.bytes=-1, retention.ms=9223372036854775807} (kafka.log.LogManager)
[2025-01-06 17:41:29,856] INFO [Partition db.history.internal-0 broker=0] No checkpointed highwatermark is found for partition db.history.internal-0 (kafka.cluster.Partition)
[2025-01-06 17:41:29,856] INFO [Partition db.history.internal-0 broker=0] Log loaded for partition db.history.internal-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:30,932] INFO Creating topic kafka.leafy_factory.factories with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:30,965] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.factories-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:30,969] INFO [LogLoader partition=kafka.leafy_factory.factories-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:30,970] INFO Created log for partition kafka.leafy_factory.factories-0 in /tmp/kafka-logs/kafka.leafy_factory.factories-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:30,970] INFO [Partition kafka.leafy_factory.factories-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.factories-0 (kafka.cluster.Partition)
[2025-01-06 17:41:30,971] INFO [Partition kafka.leafy_factory.factories-0 broker=0] Log loaded for partition kafka.leafy_factory.factories-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,076] INFO Creating topic kafka.leafy_factory.jobs with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,109] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,111] INFO [LogLoader partition=kafka.leafy_factory.jobs-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,112] INFO Created log for partition kafka.leafy_factory.jobs-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,112] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,112] INFO [Partition kafka.leafy_factory.jobs-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,221] INFO Creating topic kafka.leafy_factory.jobs_machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,255] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.jobs_machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,258] INFO [LogLoader partition=kafka.leafy_factory.jobs_machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,259] INFO Created log for partition kafka.leafy_factory.jobs_machines-0 in /tmp/kafka-logs/kafka.leafy_factory.jobs_machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,259] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.jobs_machines-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,259] INFO [Partition kafka.leafy_factory.jobs_machines-0 broker=0] Log loaded for partition kafka.leafy_factory.jobs_machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,352] INFO Creating topic kafka.leafy_factory.machines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,378] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.machines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,381] INFO [LogLoader partition=kafka.leafy_factory.machines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,381] INFO Created log for partition kafka.leafy_factory.machines-0 in /tmp/kafka-logs/kafka.leafy_factory.machines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,381] INFO [Partition kafka.leafy_factory.machines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.machines-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,382] INFO [Partition kafka.leafy_factory.machines-0 broker=0] Log loaded for partition kafka.leafy_factory.machines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,485] INFO Creating topic kafka.leafy_factory.product_cost with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,512] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.product_cost-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,515] INFO [LogLoader partition=kafka.leafy_factory.product_cost-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,515] INFO Created log for partition kafka.leafy_factory.product_cost-0 in /tmp/kafka-logs/kafka.leafy_factory.product_cost-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,516] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.product_cost-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,516] INFO [Partition kafka.leafy_factory.product_cost-0 broker=0] Log loaded for partition kafka.leafy_factory.product_cost-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,617] INFO Creating topic kafka.leafy_factory.production_lines with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,647] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.production_lines-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,650] INFO [LogLoader partition=kafka.leafy_factory.production_lines-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,650] INFO Created log for partition kafka.leafy_factory.production_lines-0 in /tmp/kafka-logs/kafka.leafy_factory.production_lines-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,651] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.production_lines-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,651] INFO [Partition kafka.leafy_factory.production_lines-0 broker=0] Log loaded for partition kafka.leafy_factory.production_lines-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,739] INFO Creating topic kafka.leafy_factory.products with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,782] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,784] INFO [LogLoader partition=kafka.leafy_factory.products-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,785] INFO Created log for partition kafka.leafy_factory.products-0 in /tmp/kafka-logs/kafka.leafy_factory.products-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,785] INFO [Partition kafka.leafy_factory.products-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,785] INFO [Partition kafka.leafy_factory.products-0 broker=0] Log loaded for partition kafka.leafy_factory.products-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,876] INFO Creating topic kafka.leafy_factory.products_raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:31,906] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.products_raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:31,909] INFO [LogLoader partition=kafka.leafy_factory.products_raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:31,910] INFO Created log for partition kafka.leafy_factory.products_raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.products_raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:31,910] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.products_raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:41:31,910] INFO [Partition kafka.leafy_factory.products_raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.products_raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:32,022] INFO Creating topic kafka.leafy_factory.raw_materials with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:32,053] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.raw_materials-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:32,056] INFO [LogLoader partition=kafka.leafy_factory.raw_materials-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:32,056] INFO Created log for partition kafka.leafy_factory.raw_materials-0 in /tmp/kafka-logs/kafka.leafy_factory.raw_materials-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:32,058] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.raw_materials-0 (kafka.cluster.Partition)
[2025-01-06 17:41:32,059] INFO [Partition kafka.leafy_factory.raw_materials-0 broker=0] Log loaded for partition kafka.leafy_factory.raw_materials-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:32,160] INFO Creating topic kafka.leafy_factory.work_orders with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2025-01-06 17:41:32,190] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(kafka.leafy_factory.work_orders-0) (kafka.server.ReplicaFetcherManager)
[2025-01-06 17:41:32,193] INFO [LogLoader partition=kafka.leafy_factory.work_orders-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2025-01-06 17:41:32,194] INFO Created log for partition kafka.leafy_factory.work_orders-0 in /tmp/kafka-logs/kafka.leafy_factory.work_orders-0 with properties {} (kafka.log.LogManager)
[2025-01-06 17:41:32,194] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] No checkpointed highwatermark is found for partition kafka.leafy_factory.work_orders-0 (kafka.cluster.Partition)
[2025-01-06 17:41:32,194] INFO [Partition kafka.leafy_factory.work_orders-0 broker=0] Log loaded for partition kafka.leafy_factory.work_orders-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-01-06 17:41:46,327] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 3 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,327] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 4 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,331] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 for group connect-cluster for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,346] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-cluster in state PreparingRebalance with old generation 4 (__consumer_offsets-13) (reason: Leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 re-joining group during Stable; client reason: ) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,347] INFO [GroupCoordinator 0]: Stabilized group connect-cluster generation 5 (__consumer_offsets-13) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,348] INFO [GroupCoordinator 0]: Assignment received from leader connect-192.168.1.5:8083-5318dcad-ceb2-4976-99ef-f23bb7484df3 for group connect-cluster for generation 5. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,395] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group connect-mongodb-sink-connector in Empty state. Created a new member id connector-consumer-mongodb-sink-connector-0-2468b6af-d9a9-40e1-9291-fbe55cf28191 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,396] INFO [GroupCoordinator 0]: Preparing to rebalance group connect-mongodb-sink-connector in state PreparingRebalance with old generation 0 (__consumer_offsets-33) (reason: Adding new member connector-consumer-mongodb-sink-connector-0-2468b6af-d9a9-40e1-9291-fbe55cf28191 with group instance id None; client reason: need to re-join with the given member-id: connector-consumer-mongodb-sink-connector-0-2468b6af-d9a9-40e1-9291-fbe55cf28191) (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,399] INFO [GroupCoordinator 0]: Stabilized group connect-mongodb-sink-connector generation 1 (__consumer_offsets-33) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2025-01-06 17:41:46,404] INFO [GroupCoordinator 0]: Assignment received from leader connector-consumer-mongodb-sink-connector-0-2468b6af-d9a9-40e1-9291-fbe55cf28191 for group connect-mongodb-sink-connector for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
